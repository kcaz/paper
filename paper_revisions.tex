\documentclass[11pt]{article}
\usepackage{graphicx}
\usepackage[pdf]{pstricks}
%\usepackage{mathtools}
\usepackage{amssymb,amsmath}
\usepackage{textcomp}
\DeclareMathOperator*{\argmin}{arg\,min}

%\usepackage{subcaption}
%\usepackage{float}
\usepackage{setspace}
\usepackage{fullpage}
\usepackage[font=scriptsize]{caption}
%\usepackage{fullpage}
%\setcounter{secnumdepth}{1}
\usepackage{amsmath}
\usepackage{algorithm}
\usepackage{algpseudocode}

\makeatletter
\def\BState{\State\hskip-\ALG@thistlm}
\makeatother


\begin{document}

\title{Fused regression for multi-source gene regulatory network inference}
\author{Kari Y. Lam\textsuperscript{1} \and Zachary M. Westrick\textsuperscript{1} \and Christian L. M\"{u}ller\textsuperscript{2}\and Lionel Christiaen\textsuperscript{1} \and Richard Bonneau\textsuperscript{1,2}}
\maketitle

  1. New York University, New York, NY 10003
  2. Simons Foundation, New York, NY 10010


\begin{abstract}
Understanding gene regulatory networks is critical to understanding cellular differentiation and response to external stimuli. Methods for global network inference have been developed and applied to a variety of species. 
Most approaches consider the problem of network inference independently in each species, despite evidence that gene regulation can be conserved even in distantly related species. 
Further, network inference is often confined to single data-types (single platforms) and single cell types. 
We introduce a method for multi-source network inference that allows simultaneous estimation of gene regulatory networks in multiple species or biological processes through the introduction of priors based on known gene relationships such as orthology incorporated using fused regression. 
This approach improves network inference performance even when orthology mapping and conservation are incomplete. 
We refine this method by presenting an algorithm that extracts the true conserved subnetwork from a larger set of potentially conserved interactions and demonstrate the utility of our method in cross species network inference. 
Last, we demonstrate our method's utility in learning from data collected on different experimental platforms.
\end{abstract}

\section{Author Summary}

Gene regulatory networks describing related biological processes are thought to share conserved interaction structure. This assumption motivates a great deal of work in model systems – where discovery of gene regulation may be more experimentally tractable – but is difficult to directly evaluate using existing methods. The presence of shared structure in a well studied model system or process should make the problem of network inference in a related process easier, but this information is not often applied to the discovery of global gene regulatory networks. Further, to be able to successfully translate findings between different organisms, it is important to be able to identify what is systematically different. We provide a method for gene regulatory network inference using data from related sources. We introduce approaches for the simultaneous inference of related networks, and the identification of conserved subnetworks. The method is benchmarked on synthetic networks, and evaluated on the problem of inferring networks in related bacterial datasets.


\section{Introduction}
As the volume and variety of genome scale data continues to increase in quantity and quality, the goal of accurately modeling gene regulatory networks has become attainable \cite{bonneau_predictive_2007, ciofani_validated_2012, carro_transcriptional_2010}. 
Large-scale data collection efforts have contributed to the development of high quality networks which accurately recapitulate biological processes, but most processes and organisms remain uncharacterized at the network level. 
Furthermore, as new technologies are developed and some old ones are replaced, such as RNAseq and microarray, it becomes important to be able to combine data from multiple platforms, lest we lose valuable information from existing studies. The problem of inferring related -- but not necessarily identical -- structure from related -- but not identical -- data is ubiquitous in biology. 
Multi-source network inference has applications for learning multiple networks in related species, for learning networks associated with distinct processes within the same species, and for learning networks based on heterogenous data sources. 
Moreover, as it becomes possible to learn genome-wide regulatory networks, we can begin to compare and to test whether there is conservation of networks across species and biological processes. 
Our use of model organisms to study biological processes and diseases relevant to humans relies on the assumption of conservation; yet this has not been effectively tested at the genome scale. 

We present two methods for network inference based on linear estimates of gene expression dynamics, extending existing dynamical-systems methods for network inference \cite{bonneau_predictive_2007, arrieta-ortiz_experimentally_2015, yeung_reverse_2002}. 
The core of both methods is the observation that biological information about the relatedness of genes can be used to select which network coefficients should be similar to one another in a multi-source network inference problem (ie orthologous TFs should regulate orthologous genes), and that these constraints can be efficiently represented as penalties in a least-squares regression problem. 
Taking into account the similarity of putatively conserved interactions improves our ability to accurately describe TF-gene relationships on a genome-wide scale.  

Our first method -- fused ridge -- uses an L2 penalty on the differences between \textit{a priori} similar interactions (termed fusion penalty), and is useful where the relationships between networks (similarity of genes between data sets) is reliable. 
In the case where both networks contain an identical set of genes and TFs, this approach can be thought of as parametrically interpolating between treating the data sources separately and combining them together. 
In the case of multi-species, simply combining two datasets is both unwise -- because the networks may differ substantially -- but also potentially impossible, because the set of common of genes may be small. 
Our method allows useful pooling of data even when the overlap between genes is incomplete, or when orthology assignments depart from a strict one-to-one mapping. Our second method -- adaptive fusion -- uses a non-concave saturating fusion penalty to simultaneously infer the constrained networks and to learn which constraints should be relaxed (ie which parts of the network are genuinely different). 
With this approach, we seek to identify both conserved and divergent interactions between related networks.

In the case of multiple species, numerous studies have shown that functional conservation exists in gene regulatory networks even across large evolutionary distance \cite{satou2006gene, hinman2009evolution,tanay2005conservation,erwin2009evolution}. 
In our fused L2 approach, we assume that for closely related species, orthologous TFs could exert similar regulatory effects on orthologous target genes. 
These orthology relationships form the basis of a set of constraints which favor -- but do not require -- networks in which orthologous transcription factors regulate orthologous genes. As a result, data in one species can improve network inference performance in another species  (and vice versa). 
This general framework for multi-species network inference can be extended to an arbitrary number of distinct organisms, each contributing data with only partially overlapping sets of genes. 
This is an advantage over existing approaches to multi-species network inference, which infer only a sub-network for which orthologs exist in every species \cite{joshi_multi-species_2015}. 

This approach of introducing constraints on the similarity between specific regulatory interactions can be extended beyond the case of multi-species network-inference from orthology; any biological prior on similarity of regulation can be used in place of orthology. 
For example, we can use fused regression to combine datasets obtained using different platforms or experimental techniques and we can introduce constraints that favor genes in the same operon (or having similar promoters) towards having similar regulators.

Existing multi species approaches often use orthology as a proxy for functional conservation \cite{roy_arboretum:_2013, penfold_inferring_2015, joshi_multi-species_2015, kashima_simultaneous_2009, zhang2010nearly}, or attempt to learn functional similarity via expression data \cite{gholami_cross-species_2010}. 
Orthology can be approximated using readily identifiable sequence similarity, which is often a useful predictor of functional similarity \cite{wilson_assessing_2000, jensen_eggnog:_2008}. 
In multi-species network inference, our fused L2 approach minimizes a cost function that strives to simultaneously fit expression data in each species and produce networks that are consistent with evolutionary constraints created using orthology. 
However, many genes will have evolved different functions and therefore may have new regulatory interactions. 
For example, gene duplications may lead to neofunctionalization \cite{eisen_phylogenomics:_1998} of the duplicated genes. 
In the case of comparing networks from related cell lines from the same species, changes in chromatin configuration may affect our hypotheses about the similarity of interactions between pleiotropic TFs and target genes across cell types (a within-species analog to neo-functionalization) \cite{li_role_2007}.
Identifying interactions that are present in one species but not another is of direct biological interest, but existing approaches to network inference are unable to effectively test the hypothesis of conserved subnetworks. 
Observing a large difference in the weights of regulatory interactions obtained though independent inference of multiple networks is perhaps the best (least biased) evidence against conservation of orthologous regulatory interactions (cases where target and regulator have orthologs across species). 
However, this is sometimes weak evidence, as network inference is typically underconstrained \cite{marbach_revealing_2010}, meaning there could be a different set of networks for which conservation does hold, and which fit the data almost as well. 
We propose using our adaptive fusion approach to simultaneously perform network inference and evaluate edge-conservation (or lack thereof). 

We approach this problem by introducing a saturating penalty function based on statistical efforts to develop unbiased regularization penalties for fused regression \cite{zhang2010nearly, fan2001variable}. 
The main difference between the L2 fusion approach and our new adaptive fusion approach occurs when the difference between presumed analogous interactions is large despite the fusion penalty. 
We assume that cases where the method is unable to reconcile the likelihood and the fusion constraint derived from orthology (in the case of multi-species fusion) or identity (in the case of multi-platform fusion) correspond to cases with evidence of divergent TF-to-target-gene interactions. 
Practically, this inability to reconcile likelihood and conservation hypothesis manifests as large differences in model weights across species or platforms. 
We account for this possibility in our adaptive fusion model with a relaxation of the fusion penalty in cases with extreme model weight divergence. 
The resulting cost function is non-convex and difficult to optimize \cite{fan2001variable}; however, we can approximate its solution and obtain deeper insight into functional similarity than is available through strict orthology enforcement or the comparison of separately learned networks. 

Although the fusion constraints we employ can be described as arising from orthology - which links genes - it is important to note that the constraints themselves link individual regulatory interactions. 
This finer level of representational granularity is critical to the functioning of adaptive fusion, and means the method can accommodate any form of prior on expected similarity between regulatory interactions, even priors that cannot be decomposed into gene to gene mappings. 
We develop two algorithms for solving efficiently multi-output least-squares regression problems with pairwise L2 fusion penalties on entries of the coefficient matrix. 
We also introduce - in the form of adaptive fusion - the idea of a saturating penalty function on fusion constraints, and estimate the solution to the resulting optimization problem through iterative application of the fused L2 algorithm.

We test the ability of fused L2 and adaptive fusion to improve network recovery on both synthetic data and by comparing related networks in the bacteria species \textit{Bacillus subtilis} and \textit{Bacillus anthracis}. 
This shows the applicability of our method in combining different datasets and leveraging similarity across organisms as well as within a network in order to improve network inference. We explore the circumstances under which each approach is optimal, and evaluate the robustness of adaptive fusion to incorrect orthology, simulating the biologically relevant cases of neo- and sub-functionalizations. 


\section{Methods}

\subsection{Statistical approach and background}
We consider prediction and coefficient estimation problems with $N$ observations of $M$ dependent variables $y_{1,1}, y_{2,1}, ...y_{N,1}, y_{N,2},..., y_{N, M}$ and $p$ features $x_{i,j}$, $i=1,2,...,N, j=1,2,...,p$. We begin with a standard linear regression model:

\begin{equation}
y_{i,k} = \displaystyle\sum_{j}x_{ij}\beta_{j,k} + \epsilon_i
\end{equation}

with errors $\epsilon_i$ having mean 0 and constant variance, and predictors $x_{ij}$ having mean 0 and unit variance. We are interested in the case where $p > N$. Many methods have been proposed to deal with the underconstrained case, and have been applied to genomic data \cite{waldron_optimized_2011, li_network-constrained_2008}. For example, ridge regression penalizes the L2 norm of the coefficients $\beta_{i,j}$ in order to avoid overfitting \cite{hoerl_ridge_1970}, and can be thought of as a mean-zero Gaussian prior on the coefficients. 
More complicated penalties have been developed to represent specific expected or desireable structure in a regression model's coefficients. 
For example, Land and Friedman \cite{citeulike3780356} proposed a fusion penalty which encourages smoothness of the estimated parameter vector. Previous approaches have used  fusion penalties to draw statistical strength across multiple regression tasks \cite{kim_tree-guided_2012,Land1997,Chen2010,Petry2011,Hebiri2011}. 
Price et al. and Bilgrau et al. use a fused ridge estimator for jointly estimating multiple inverse covariance matrices \cite{Price2014a,Bilgrau2015}.
We take a related approach to these prior works, adding an L2 penalty on the differences between coefficients to the existing ridge penalty in order to incorporate prior knowledge about relationships between input-output pairs:

\begin{equation}
\argmin_{\beta} \displaystyle\sum \vert \vert X\beta - Y \vert \vert ^2 + \lambda_R \vert \vert \beta \vert \vert ^2 +  \lambda_S  \displaystyle \sum_{\beta_{g,k} \approx \beta_{h,l}} || \beta_{g,k} - \beta_{h,l} ||^2
\label{eqn:main}
\end{equation}

where $X$, $Y$, and $\beta$ are matrices, and $\beta_{g,k} \approx \beta_{h,l}$ denotes fusion between entries of $\beta$ (enforcing similarity between model weights across separate data-sets). 
Note that, like ridge regression, this penalty can be thought of as representing a Gaussian prior on the coefficients $\beta$. 
In the case where $\beta$ is a column vector, introducing this penalty is equivalent to assuming that $\beta$ is sampled from a multivariate Gaussian with inverse covariance matrix $\Sigma^{-1} = \lambda_R + \displaystyle \sum_{\beta_g \approx \beta_g} \lambda_S (1_{g,g} + 1_{h,h} - 1_{g,h} - 1_{h,g})$, where $I$ denotes the identity matrix and $1_{i,j}$ a matrix of zeros with 1 in its $i, jth$ entry. 
In the case of a two-coefficient model with fusion between the coefficients, for example, fused L2 is equivalent to assuming a prior with variance $(\lambda_R + \lambda_S)/(\lambda_R^2+2\lambda_R\lambda_S)$ and covariance $\lambda_S/(\lambda_R^2+2\lambda_R\lambda_S)$.


In many cases, however, there is some uncertainty about the relationships that should be enforced. 
Sohn et al. attempt to simultaneously learn the regression coefficients and the output structure \cite{sohn_joint_2012}. 
We develop a similar approach, by applying a penalty function bounded by a constant to produce unbiased estimators for large coefficients, combined with an L2 penalty, similar to SCAD-L2 \cite{Zeng2012}. 

\begin{equation}
\argmin_{\beta} \displaystyle\sum \vert \vert X\beta - Y \vert \vert ^2 + \lambda_R \vert \vert \beta \vert \vert ^2 + \displaystyle \lambda_S  \displaystyle \sum_{\beta_{g,k} \approx \beta_{h,l}} p_{\lambda, a} (\beta_{g,k} - \beta_{h,l})
\end{equation}

where the penalty $p_{\lambda, a}$ has derivative 

\begin{equation}
p'_{\lambda,a}(\theta) = \left\{
    \begin{array}{lr}
    \lambda\theta & \text{if } \theta \leq \lambda\\
    \text{max}(\lambda(2a-\theta),0) & \text{if } \theta > a}
    \end{array}
    \right.
\end{equation}

 This approach allows us to simultaneously learn the regression coefficients and evaluate the validity of our prior information (this model relaxes the fusion penalty when model components are irreconcilably different). 

\subsection{Application}
Although our approach is generalizable to a wide variety of multi-source network inference problems, we begin with the concrete example of network inference in two related species. 
Our approach to multi-species network inference is based on the hypothesis that gene regulation in related species is governed by similar but not necessarily identical gene regulatory networks, due to conservation of function through evolution. 
We represent conservation of network function by introducing constraints into the objective function for network inference that penalize differences between the weights of regulatory interactions believed to be conserved. 
These constraints favor the generation of similar networks for related species, and in the generally under-constrained regime of network inference can improve the accuracy of network recovery. 
We then go on to introduce a method to test the assumption of conserved network structure, and to relax the associated constraints on pairs of interactions for which the data does not support conservation (where conservation of a regulatory edge is implied by like model weights across data-sets).


\subsection{Approach overview}
\begin{algorithm}
	\caption{Network inference using fused regression}\label{euclid}
	\begin{algorithmic}
%\Procedure{MyProcedure}{}
\State load expression data
\State load orthology
\State create priors and fusion constraints
\State partition gold standard into training and leave-out
\State generate TFA matrices using gold standard training set
\State set $a$ if using adaptive fusion
\For{$k$ in folds}
	\State partition expression data into training and leave-out set
	\State $\lambda_R$ parameter selection using training set
	\State $\lambda_S$ parameter selection using training set
	\State run fused regression
	\State return PRC and ROC curves using leaveout gold standard
	\EndFor
\State average PRC / ROC curves over folds
\EndProcedure
\end{algorithmic}
\end{algorithm}


\subsection{Gene regulatory network}

We model the transcription rate of each gene as a weighted sum of transcription factor expression, and seek to identify the identities and regulatory weights of these TFs. 
This formulation matches that of the existing \textit{Inferelator} algorithm, which models gene expression with linear differential equations \cite{bonneau_inferelator:_2006-1}. Our primary data for learning gene regulatory networks is expression data, consisting of time-series and steady state experiments. 
The rate at which $x_{i}$, the observed mRNA expression of gene $i$, changes, is governed by degradation of existing transcripts with rate $\alpha$ plus a linear combination of transcription factor (TF) expressions. 
\begin{equation}
\frac{\mathrm d}{\mathrm d t} x_i = -\alpha_{i}x_{i} + \sum \beta_{i,j}x_{j}
\end{equation}
where $\beta_{i,j}$ represents the weight of TF $j$ on gene $i$, and $\alpha$ is the decay rate of gene $i$. We fix the decay rate $\alpha$ for all genes, and set it assuming a time-constant of 10 minutes \cite{hambraeus_genome-wide_2003, selinger_global_2003}, as in \cite{greenfield_robust_2013}. Let $x_i(t)$ be the expression of gene $i$ at time $t$. 
Given time-series data on the expression of gene $i$ at timepoints $t_k$ and $t_{k+1}$, we can approximate the rate of change of $x_i$ as $x_i'(t_k)=\frac{x_i(t_{k+1})-x_i(t_k)}{t_{k+1}-t_k}$. 
We treat steady-state data as having a derivative of zero. 
This gives us, for each gene $i$ and time $t_{k}$ an equation

\begin{equation}
\frac{x_i(t_{k+1})-x_i(t_k)}{t_{k+1}-t_k} + \alpha_{i}x_{i}(t_k)= \sum \beta_{i,j}x_{j}(t_k)
\end{equation}
where $j \neq i$ 
for time series and 
\begin{equation}
\alpha_{i}x_{i}(t_k) = \sum \beta_{i,j}x_{j}(t_k)
\end{equation}
for steady state. 


\noindent We can summarize these equations in matrix form as
\begin{equation}
Y = X \beta 
\end{equation}
where $Y$ is the gene expression matrix, $X$ is the TF expression matrix, and $\beta$ is the regulatory weights we are interested in learning.
We are interested in learning $\beta$, the matrix representation of the gene regulatory network, where the weight in a given position represents the regulatory weight of a TF on a gene. 
Positive weights represent activation, negative weights represent repression, and 0 weights represent the absence of an interaction. The matrix $\beta$ can be solved using linear regression. 
Because there are typically far fewer conditions than possible regressors (TFs), we introduce a ridge regularization constraint with weight $\lambda_R$ and solve
\begin{equation}
\argmin_\beta\vert \vert X\beta - Y_2 \vert \vert ^2 + \lambda_R \vert \vert \beta \vert \vert ^2
\end{equation}
This is similar to the formulation used in the \textit{Inferelator} algorithm, which we extend to the case of simultaneously inferring multiple networks.

Transcription factor expression is not always the best predictor of its gene targets' expression, so  previous network inference methods attempt to estimate transcription factor activities prior to network inference. 
When there exists a set of prior known interactions, we are able to estimate transcription factor activity (TFA) using network component analysis \cite{liao2003network}, as in \cite{arrieta-ortiz_experimentally_2015, fu_reconstructing_2011}, and use TFA as explanatory variables instead of transcription factor expression. 


\subsection{Fused gene regulatory networks}

Information about the partially conserved structure of gene regulation is introduced through the incorporation of constraints into the above regression formulation. These constraints penalize differences between interaction weights in the networks of multiple species that are expected to be similar based on prior biological knowledge. 
We can then solve the penalized regression problems simultaneously, in order to obtain a gene regulatory network (GRN) for each species. 
Consider the case of organisms $A$ and $B$, governed by GRNs $\beta^A$ and $\beta^B$ (the following approach applies equally well to more than two species but for simplicity we continue with the case of two species). 
When TF $g^A$ in organism $A$ and TF $h^B$ in organism $B$ are orthologs, and gene $k^A$ and $l^B$ are orthologs, then we expect that the $g^A \rightarrow k^A$ interaction weight should be similar to the $h^B \rightarrow l^B$ interaction weight, and we introduce a fusion constraint between these analogous interactions. 
In terms of the above regression formulation, we expect that $\beta^A_{g,k} \approx \beta^B_{h,l}$, and include a penalty term $\lambda_Sp(\beta^A_{g,k} - \beta^B_{h,l})$ in the quantity being minimized in order to encourage similarity. 
The function $p(x)$ controls the shape of the relationship between weight dissimilarity and penalty, while scalar $\lambda_S$ controls the overall scaling of the penalization of differences between fused coefficients. $\lambda_S$ controls the tradeoff between fitting the expression data-sets individually and producing a set of networks that conform to evolutionary prior knowledge. 
This gives us the final equation to be minimized: 

\begin{equation}
\argmin_{\beta^S} \displaystyle\sum_{S \in \{1, 2\}} \vert \vert X^S\beta^S - Y^S \vert \vert ^2 + \lambda_R \vert \vert \beta^S \vert \vert ^2 + \lambda_S \displaystyle \sum_{\substack{(g,h) \in orth,\\
 (k,l) \in orth}}p(\beta^{S_1}_{g,k} - \beta^{S_2}_{h,l})
\end{equation}

where the second sum is over pairs of interactions with fusion constraints. 
In the fused L2 algorithm presented here, the penalty function is equal to the L2 norm of the difference in regulatory weight of fused coefficients, $p(x)=x^2$. 
Every component of the objective function is an L2 norm and thus the problem is convex and can in fact be solved through linear regression with an augmented design matrix. 

As an example, consider the case where there is a one-to-one orthology between the species being considered (ie different cell-lines of the same organism). 
The choice of $\lambda_S$ allows one to interpolate between fitting each network independently ($\lambda_S=0$) and pooling data together as if it came from one source ($\lambda_S=\inf$). 
In addition to performing well between these extremes, our method allows pooling of data even when there is incomplete orthology. 
By introducing constraints on the similarity of individual interactions, rather than on the networks as a whole \cite{parikh2011treegl}, we can pool some information across species even when a small fraction of genes have orthologs. 


\subsection{Adaptive fusion}
Fusion constraints penalize dissimilarity between interactions thought to be analogous based on \textit{a priori} knowledge. 
For example, orthology can be used to predict which interactions will be similar across species. 
With an L2 fusion penalty, interaction weights which differ from each other by a large amount are excessively penalized, which effectively ensures that fused interactions are assigned similar weights. 
This will be inappropriate for interactions which are identified based on orthology as being analogous, but which are no longer similar due to evolutionary changes. 
We propose that a saturating penalty  that is relaxed once differences in weights grow beyond a certain point (interactions which appear to be very different based on the data are effectively unfused). 
A related problem has been studied in the context of LASSO regularization, where it was shown by Fan and Li that using a saturating penalty retains many of LASSO's desireable properties while removing its bias towards model weights of 0 \cite{fan2001variable}. 
They further showed that, although the resulting loss-function is nonconvex, good results can be obtained with a local quadratic approximation of gradient descent. Several saturating penalties, such as SCAD \cite{fan2001variable} and MCP \cite{zhang2010nearly}, have been discussed in the context of sparse regression. 
We introduce a modified form of MCP to the problem of penalizing differences between fused coefficients. 
The principal difference between the penalty we adopt and SCAD/MCP is that both of these penalties are L1 like at the origin, producing sparse solutions. 
Some network inference approaches use L1 penalties to produce sparse networks, on the basis that biological networks are thought to be sparse. 
However, as we are penalizing differences in interaction weights, rather than the weights themselves, there's no reason to assume that most differences will be exactly zero, and an L2 penalty - equivalent to an assumption that the differences between fused coefficients are Gaussian distributed - may be more appropriate.

We use a penalty on the difference between fused coefficients $\theta$ which is L2 like at the origin and saturates at $\theta = a$. Written in terms of its derivative, the penalty $p'_{\lambda, a}$

\begin{equation}
p'_{\lambda,a}(\theta) = \left\{
    \begin{array}{lr}
    \lambda\theta & \text{if } \theta \leq \lambda\\
    \text{max}(\lambda(2a-\theta),0) & \text{if } \theta > a}
    \end{array}
    \right.
\end{equation}
    
As in \cite{fan2001variable}, we solve using iterative local quadratic approximation. Specifically, $\beta^S(t)$ is the network on iteration $t$. For each fused $B^{S_1}_{g,k} \approx B^{S_2}_{h,l}$ we define:

\begin{equation} 
\theta(0)=0
\end{equation}
\begin{equation}
\theta(t) = \vert B^{S_1}_{g,k} - B^{S_2}_{h,l} \vert
\end{equation}

and introduce a fusion constraint $\lambda = \frac{p'(\theta(t))}{2\theta(t)} $

$\beta^S(t+1)$ is obtained by fitting the ridge-fused model with fusion constraints given by the above $\lambda_S$. This is useful because all our penalties can be treated as L2 and therefore retain the properties of ridge regression, and can be solved using the fused L2 algorithm we develop.

Our adaptive penalty function introduces, in addition to regularization and fusion penalty weights $\lambda_R$ and $\lambda_S$, an unknown parameter $a$.
We could employ grid search using cross-validation to search for the best parameters, but for many data sets, this can be computationally expensive. 
Moreover, we are primarily interested in using this saturating penalty as a way of testing the hypothesis that conservation in GRNs can be predicted based off of known similarities between genes. 
Therefore, we propose a user-defined $a$, where this parameter is set using the distribution of differences between fused weights from independently fit networks. The choice of which value in this distribution to use for $a$ represents the working hypothesis for the fraction of fused interactions which should be unfused.


\subsection{Solving fused L2 problems using augmented matrices}
We begin with the problem of constructing a design matrix to map our problem to that of solving a fused L2 regression problem with a single response variable. 
We then go on to show that, although the vectorized solution involves solving an impractically large system of equations, under typical biological conditions the structure of constraints allow the problem to be broken up into many smaller subproblems. 
Key to this approach is the observation that ridge constraints can be incorporated into a least-squares regression problem by appending a scaled identity matrix to the design matrix, and a corresponding number of zeros to the response vector. 
Similarly, a fusion constraint $\lambda_S (\beta_{i} - \beta{j})^2$ can be incorporated into a least-squares regression problem by appending a row containing $\sqrt{\lambda_S}$ in the $i$th position, $-\sqrt{\lambda_S}$ in the $j$th position, and $0$s elsewhere to the design matrix, and zero to the response vector. 
In order to convert an optimization over multiple response variables and multiple sources into an optimization with a single source and response variable, we vectorize as follows: we construct a new design matrix by diagonally concatenating design matrices from relevant regression problems, and create a new response vector by concatenation of corresponding response vectors. 

This is equivalent to the original problem due to the block structure of matrix multiplication. 
In an ordinary regression problem each response variable can be solved independently, and vectorization is unnecessary. 
However, in fused regression, we append additional rows to the design matrix that link entries of the interaction weight matrix associated with different response variables (figure \ref{cartoon}). 
As a result, these linked response variables must be solved simultaneously through vectorization. 
Two response variables are linked by a fusion constraint if any of the regulatory weights affecting those genes are linked by a fusion constraint. 
Two response variables must be solved simultaneously if there is any chain of linked response variables connecting them. 
However, every other response variable can be solved separately. 
In biological terms, the regulators of two genes (whether in the same species, or different species) must be solved together if there is a fusion constraint linking those genes' regulators, or if there is a chain of such constraints. 
If the networks for a large number of genes are solved simultaneously, the system of equations can quickly become intractable. 

In order to avoid this difficulty, we use depth-first search to identify linked columns of each TF expression matrix, then form design and response matrices through vectorization. 
We can then incorporate fusion constraints as in the case of single-source single response-variable fused regression. 
In most cases, we have found the direct solution using augmented matrices to be adequate (possible due to the sparse structure of orthology links; only a small number of genes must be solved at once). 
In the general case, the size of the design matrix is proportional to the number of response variables that must be solved simultaneously. 
Because the scaling of this algorithm has a complicated dependence on the constraint structure used, a general description of its runtime is difficult. 
However, in the case of multi-species network inference with one-to-one orthology, the network associated with each pair of orthologous genes requires solving a linear system with approximately twice as many observations and unknowns as the single species case. 
Linear systems of this size can be solved quickly using standard techniques, and runtime using our bacterial datasets clocks in around thirty minutes. 
When the size of the groups of genes linked by fusion constraints becomes large (when organisms have a number of many-to-many orthologous blocks), however, the augmented design matrix approach becomes slower and we discuss further optimisations to this scheme below to enable scaling to these regimes.


\subsection{Solving fused L2 problems using iterative solver}

To address scaling limitations when many-to-many fusion constraint blocks occur, we developed an iterative solver that uses coordinate-wise descent to solve for solutions corresponding to a sequence of values of fusion penalty weights. 
As our fused L2 method uses a convex and differentiable penalty function, this approach converges to a global minimizer. 
Although less efficient than the augmented design matrix approach we developed for cases where fusion constraints are primarily one-to-one or few-to-few, the iterative solver has the advantage of computing a solution path for $\lambda_S$ and scaling well across a wider range of biological applications.

On each iteration $t$ the iterative solver computes

\begin{equation}
\argmin_{\beta^S} \displaystyle\sum_{S \in \{1, 2\}} ||X^{S}\beta^{S}(t) - Y^{S}||^2 + \lambda_R||\beta^{S}(t)||^2 + \lambda_S\displaystyle \sum_{\substack{(g,h) \in orth,\\
 (h,l) \in orth}} ||\beta^{S}_{g,k}(t) - \beta_{h,l}^{S}(t-1)||^2
\end{equation}
Note that this is almost identical to equation 5, but now the network $\beta$ is a function of the iteration number $t$. On each step, we compute $\beta$s that minimize a penalized cost function where the fusion penalties encourage similarity between a parameter and its fused-to parameter from the previous iteration's solution. 
This process is iterated until the estimated $\beta$s converge. 
Because each iteration reduces the error between $\beta(t)$ and $\beta(t-1)$, and because $\beta(t) = \beta(t-1)$ is the globally optimal solution, this process must eventually converge to the same network as equation \ref{eqn:main}. 
Although we have not produced bounds on the convergence rate, which also depends on the structure of constraints, in practice a small number of iterations ($\sim$10) are necessary.


\subsection{Fusion and regularization path}
Optimizing over both parameters, $\lambda_R$ and $\lambda_S$, is computationally prohibitive and we opted to test a heuristic where we optimize the two parameters separately. 
Our procedure first optimized $\lambda_R$ with $\lambda_S=0$, then optimized $\lambda_S$ using this value of $\lambda_R$. 
This procedure is guaranteed to achieve the best unfused solution in the case when $\lambda_S$ is constrained at 0. 
As a result, any performance gains of fused regression are a lower bound on the highest achievable performance gains. 
To optimize $\lambda_R$ we use cyclical coordinate descent algorithms from the 'glmnet' package \cite{friedman_regularization_2010} to compute a ridge regularization path. 
We use cross validation to select the optimal $\lambda_R$ parameter from this path, selecting the $\lambda_R$ which minimizes the average error of prediction on a leave out set across cross validation folds. 
Following selection of $\lambda_R$, we search for optimal $\lambda_S$ by computing the solution path from the iterative solver (using the sequence of successive model weights) again using cross validation to select the optimal parameter. 
Note that both parameters are chosen without reference to the gold standard, which is used in a separate evaluation of network quality. 


\subsection{Simulated data}
We generate simulated data to evaluate the ability of our fused L2 approach to learn the true network and to show that sharing information between similar but not identical data sources results in more accurate network recovery. 
Generation of simulated data begins with the production of random orthology mappings with sparcity simlar to that found in real data-sets. 
We produce a one-to-one orthology by pairing random genes until a specified fraction have been assigned orthologs. 
This process is carried out separately for TFs and non-TF genes, so that TFs and non-TF genes are never assigned to be orthologous. 
We then produce a pair of random networks ($\beta^1$ and $\beta^2$) as follows. For each unfilled entry in $\beta^1$ or $\beta^2$, we enumerate the set $C$ consisting of the entry along with every entry in either matrix to which it is fused. 
With probability equal to the sparsity rate we assign every entry in $C$ to be 0, otherwise we sample a value $v \sim \mathcal{N}(0,1)$ and independently assign each entry in $C$ to $v + \mathcal{N}(0, \sigma_f^2)$. $\sigma_f$ is a parameter that controls the distribution of differences in the values of fused coefficients, so that the nonzero coefficients of $\beta^1, \beta^2$ are distributed as $\mathcal{N}(0, 1 + \sigma_f^2)$.

Given a network $\beta$, we generate $N$ samples of gene expressions at two timepoints. 
The condition by gene expression matrix for timepoint one, $Y_{T1}$, is sampled randomly from a multivariate Gaussian distribution with identity covariance matrix. $X_{T1}$ is the TF expression sub-matrix of $Y_{T1}$, and consists of columns of $Y_{T1}$ that correspond to TFs. 
Treating the decay rate as 0, the gene expression matrix at timepoint two, $Y_{T2}$ is sampled as $Y_{T2} = Y_{T1} + \betaX_{T1} + \epsilon$, where $\epsilon$ is a Gaussian noise term. 
This process is carried out separately for each network. 
Following generation of simulated data, we may introduce error into the orthology mapping. 
This can take the form of discarding a specified fraction of true orthologies (governed by a false-negative rate), by introducing random false orthologies (governed by a false-positive rate), or by adding Gaussian noise so that fused interactions are not identical (described above). 
For convenience, the false-positive rate is specified in units of the number of true orthologs, and not the number of possible orthologs. 
The list of priors can in a similar fashion be manipulated to include false positives and false negatives. 

\subsection{Ranking regulatory hypotheses}
In previous work, betas were rescaled as to form a matrix of confidence scores $S$ as follows
\begin{equation}
S_{i,j} = \frac{\sigma^2_{\text{full model for }y_j}}{\sigma^2_{\text{full model for }y_j \text{ without predictor }i}}
\end{equation}
Computing residuals with respect to the data alone would disregard information gained through fusion, because certain interactions may be large due to fusion, rather than their individual explanatory power. Instead, we used an approximation
\begin{equation}
S_{i,j} = \frac{\sigma^2_{\text{full model for }y_j}}{\sigma^2_{\text{full model for }y_j} + \beta_{i,j}^2 \times var(TF_j)}
\end{equation}

\subsection{\textit{B. subtilis} and \textit{B. anthracis} data and orthology}
We used a dataset collected for PY79, a derivative of strain 168, available on GEO with accession number GSE67023, and a dataset using BSB1, another derivative of strain 168, available at GEO with accession number GSE27219. 
We used two datasets for \textit{B. anthracis}, transcription profiling during iron starvation (E-MEXP-2272 on ArrayExpress), and time series over the life cycle (E-MEXP-788 on ArayExpress). We ran Inparanoid to obtain orthology mapping for \textit{B. subtilis} and \textit{B. anthracis} \cite{ostlund_inparanoid_2010}

\section{Results}
We used both synthetic networks and real data to test the ability of fused regression to improve the performance of network inference, and the ability of our adaptive fusion procedure to identify conserved interactions between orthologous genes. 
For the synthetic data, we generated random pairs of networks in which orthologous genes have similar regulatory interactions, and then sampled gene expression from these networks, which we used to derive learned networks for comparison with the input (true) networks. 
For real data, we computed recovery of a known gold standard in \textit{Bacillus subtilis} \cite{michna_subtiwikidatabase_2014}. 

\subsection{Using fused regression to learn related networks}
It is known that the accuracy of network inference improves with additional data \cite{bar-joseph_computational_2003}. 
Using related data for network inference allows us to leverage statistical power from disparate sources, effectively increasing the sample size and boosting the sensitivity and specificity of learned interactions. 
We created synthetic networks to approximate two related biological processes, then evaluated performance of our fused L2 regression, which learns the networks simultaneously given a prior on the relatedness of interactions. 
We compared recovery of the artificial 10 TFs by 200 genes networks, using fused L2 versus learning networks separately, and varied the amounts of simulated expression data samples made available to the solver. 
When the amount of data from the second species was held constant, increasing the amount of data available for learning the network for the first species resulted in a more accurate network prediction, as expected  (figure \ref{fusion}b). 
When we increased the amount of data from the second species, we obtained performance gains on network one using fused L2 regression, demonstrating our ability to improve network inference on one dataset through incorporation of a related dataset.


\subsection{Fused regression improves performance on both the constrained and non-constrained parts of the network}
Our approach is useful for learning networks from similar sources such as related cell types from the same species, where there exists a one-to-one mapping of genes, as well as datasets where the orthology mapping does not span all genes. 
This can occur when using different technology, eg microarray and RNAseq, where there is incomplete overlap in the genes that each method assays as well as incomplete overlap in the genes expressed in different experimental designs.  
When orthology is incomplete we are interested in knowing if performance gains from fused regression are limited to those interactions which have fusion constraints, or if they extend to the entire network. 
To test this we used multiple 20 TF by 200 gene synthetic networks with varying proportions of orthologous TFs and genes. 
We divided networks into those interactions with fusion constraints (the constrained subnetwork) and interactions without fusion constraints (the non-constrained subnetwork). 
We varied the weight on the fusion penalty, $\lambda_S$, and evaluated performance by computing AUPR on the constrained subnetwork, the non-constrained subnetwork, and the whole network (figure \ref{fusion}c). 
Since the conserved subgraphs were similar to each other, we expected performance to improve as the fusion penalty weight increased. 
We observed this, particularly for the constrained subnetwork. 
As $\lambda_S$ increased, interactions with fusion constraints were encouraged to be more similar. 
Interestingly, performance gains were seen even in the portion of the network that was unconstrained by fusion. This is because a gene may have some some interactions that are constrained by fusion - regulation by TFs with orthologs - and some interactions that are unconstrained - regulation by TFs without orthologs. Because both constrained and unconstrained components compete to explain the same pattern of gene expression, improving recovery of the constrained sub-network will tend to improve recovery for the unconstrained sub-network as well.


\subsection{Adaptive fusion successfully identifies and unfuses 'neofunctionalized' genes}
Orthology prediction is not a proxy for functional conservation \cite{gabaldon_functional_2013, studer_how_2009, nehrt_testing_2011}. 
To allow for orthologous genes to be unfused we implemented an adaptive fusion algorithm that attempts to optimize a nonconvex saturating penalty function on differences between fused interactions (figure \ref{adapt-schematic}). 
Pairs of interactions that are dissimilar even after fusion, which sit in the flat portion of this penalty function, are effectively ``unfused,'' and no further penalty is incurred as differences in interaction weights grow. 
Our network procedure strongly favors similarity of fused interactions, and only ``unfuses'' interactions when their similarity cannot be reconciled with expression data. 
As a result, the ``unfusing'' or relaxation of the fusion penalty on certain constraints is much more direct evidence for neofunctionalization than comparing separately fit networks could provide. 

We performed a simulation to assess the ability of our adaptive fusion algorithm to distinguish which parts of two input networks are conserved vs. neofunctionalized (figure \ref{adaptivefusion}). We generated synthetic fused networks and introduced error in the fusion constraints by adding false positives and negatives to the orthology information given to the solver. 
Because we knew which entries in the orthology mapping were ``incorrect'' (not reflected in the generation of the networks), we could correctly label fusion constraints that involved one or more ``incorrect'' mappings. 
We verified that adaptive-fusion unfused mostly ``incorrectly fused'' interactions (figure \ref{adaptivefusion}a red dots), while leaving truly analogous interactions fused (figure \ref{adaptivefusion}a green dots). 

We then compared the recovery of interaction weights which were accurately fused, and recovery of interaction weights which were inaccurately fused due to incorrect orthology information (figure \ref{adaptivefusion}b). 
Because fused L2 heavily penalizes large differences between weights which are predicted to be similar, it is able to retrieve a more accurate network for those interactions with true fusion constraints than by learning networks separately (measured by MSE between the true and inferred interaction weights) . 
In this simulation, however, the gains accomplished through fused regression do not extend to those interactions lacking true fusion constraints, and the error remains similar to learning networks separately. When we applied adaptive fusion, we did not observe an improvement in network recovery (relative to fused L2). 
However, we were able to identify fusion constraints reflecting incorrect orthology information that had been provided to the algorithm (figure \ref{adaptivefusion}subsection). 

\c{Cross-species network inference using bacterial data}
We used gene-expression data from \textit{Bacillus subtilis} and \textit{B. anthracis} in order to assess performance gains of fused regression on real data. 
Our \textit{B subtilis} data set consists of 360 time-series and steady-state observations of 4891 genes, 4100 of which are protein coding \cite{kunst_complete_1997}, during the life cycle.
Our \textit{\textit{B. anthracis}} dataset consists of 72 time-series and steady-state observations of 5536 genes comprising data from distinct points in the life cycle and iron-starvation conditions. 
There were 247 known transcription factors (TFs) in the \textit{\textit{B. subtilis}} dataset, and 248 TFs in the \textit{B. anthracis} dataset.
We obtained 1,870 one-to-one orthologs from Inparanoid \cite{ostlund_inparanoid_2010}, 95 of which are transcription factors, which produced 177,650 fusion-constraints between gene interactions within the two species. 
This number represents only $14.7\%$ of the regulatory interaction matrix in \textit{B. subtilis} and $12.9\%$ in \textit{B. anthracis}. 

To assess network inference performance, and for use as priors, we used a gold standard of 3,040 known \textit{B. subtilis} interactions with corresponding activation and repression sign. 
Of these 3,040 priors, 968 had corresponding interactions in \textit{B. anthracis}. 
Based on our simulation results, we can expect the greatest gains in network-inference performance from fusion when the species of interest has a small number of available conditions, but data is abundant in a related species. 
However, in order to evaluate performance objectively a gold-standard of known interactions is necessary. 
As a result, we can only evaluate network recovery for \textit{B. subtilis}, and \textit{B. subtilis} also has the majority of our conditions. 
In order to simulate the data-poor regime, we subsampled our \textit{B. subtilis} data. 
We divided our \textit{B. subtilis} data into $k$ folds, and then for each fold fit a network to the \textit{B. subtilis} data from that fold alone fused to the entire 72 \textit{B. anthracis} conditions (figure \ref{xspecies-real}a). 
Though overall performance is hindered by our subsampling of \textit{B. subtilis} data (a necessary procedure to allow evaluation of networks) we demonstrate marked improvement in learning the \textit{B. subtilis} network when using fused regression (figure \ref{xspecies-real}a). 
Notably, these performance gains occur mostly at low values of recall (near the top of our prediction ranks, where biologists would presumably focus validation and followup experiments). 

\subsection{Testing adaptive fusion using bacterial data}
 The goal of adaptive fusion is to unfuse constraints between non-conserved interactions, while leaving intact all other constraints. 
 However, because we lacked a comprehensive gold standard of known non-conserved interactions between \textit{B. subtilis} and \textit{B. anthracis}, we were unable to directly evaluate how accurately adaptive fusion identified these interactions.
  We opted instead to introduce a large number of random fusion constraints between genes not known to be orthologous. 
 These fake constraints, which are unlikely to reflect any conserved network structure, served as a proxy for the unknown fraction of non-conserved interactions between orthologous genes. 
 We ran adaptive fusion to learn networks for \textit{B. subtilis} and \textit{B. anthracis}, using these constraints, along with those generated by known orthology. 
 We confirmed that our injected spurious fusion constraints were unfused at a higher rate than those generated by known orthologs (see figure \ref{xspecies-real}b & c). 
 Although it may seem odd that a large fraction of fake constraints were left intact, we note that biological networks tend to be sparse, so that many of the random fusion constraints are between coefficients with near zero weight (and therefore near zero difference in weight) (figure \ref{xspecies-real}c). 


\subsection{Integrating datasets from different platforms using fused regression}
Although there are many large-scale collaborations which attempt to make protocols as uniform as possible for comparability between datasets generated by different labs \cite{paten_nih_2015,kundaje_integrative_2015} and several methods for removing batch effects \cite{irizarry_exploration_2003,johnson_adjusting_2007}, there still exists technical and biologial variability between many experiments attempting to capture the same or similar experimental conditions esspecially when experiments employ different experimental platforms. 
With the advent of RNAseq, for example, microarray based technologies are no longer the dominant assay for genome-wide expression, but a large body of accumulated legacy data remains useful if it can be integrated with more modern techniques. 
Currently, the most widely used approach to combining datasets for network inference is to learn networks from disparate datasets separately, then rank combine the networks as in Marbach et al \cite{marbach_revealing_2010}.
We included, along with our \textit{B. subtilis} dataset, a previously published dataset containing 269 samples covering 104 conditions, obtained using a different tiling microarray (vs custom microarray) and different strain of \textit{B. subtilis} \cite{nicolas2012condition}. 
We compared performance when learning the networks separately and then rank combining (as in cite Ciofani) to learning the networks simultaneously using fusion regression and show large improvement in performance using our fused L2 approach (figure \ref{fusedl2-real}a). 

Information about the similarity of TF-gene interactions can also come from knowledge about the promoter region or the structure, for bacteria, of polycistronic transcripts. 
In bacteria, genes within the same operon are typically under the control of the same promoter \cite{lawrence_shared_2002}. 
We posited, therefore, that genes within the same operon will be regulated similarly by the same transcription factors. 
We applied fusion regression by creating fusion constraints between a given transcription factor and genes within the same operon, and showed a boost in \textit{B. subtilis} network recovery using within-species fusion (figure \ref{fusedl2-real}b). 

\subsection{Transcription factor activity estimation integrates into fusion regression approach}
We tested a combination of our fused regression approach with a method for estimating transcription factor activities (TFA). 
Rather than modeling gene expression using transcription factor mRNA abundance, we fit gene expression as a function of transcription factor activity, as applied to \textit{B. subtilis} by Arrieta-Ortiz et al \cite{arrieta-ortiz_experimentally_2015}. 
TFA activity estimates  transcription factor activities that are modulated through mechanisms such as dimerization and interaction with required factors.
TFA activity estimates have been shown prior to be better predictors of TF function than expression level alone in several contexts including similar network inference tasks\cite{fu_reconstructing_2011} \cite{arrieta-ortiz_experimentally_2015}. 
We estimate TFA based on known regulatory interactions using network component analysis \cite{liao2003network}.
To test the integration of this approach with our fused regression, we assessed the combination of \textit{B. subtilis} datasets, as in figure \ref{fusedl2-real}a, with the incorporation of TFA estimation. 
We randomly divided the prior known interactions in half, and used half to learn TFA and to generate priors on network structure. 
The remaining interactions were reserved as a gold standard for validation. 
As in previous studies, we observed a marked improvement in network inference when using transcription factor activity (figure \ref{tfa}). 
We also obtained AUPR improvement when using fused regression on TFA, and showed that our gains from sharing information across datasets using fused regression were preserved and even enhanced by using TFA. 

\section{Discussion}
Gene expression data, such as microarray or RNA seq, provide information about the relationship between genes by allowing an experimenter to measure correlations in expression value over time or across conditions. Many sources of information - such as the knowledge that two genes are related through orthology or belong to the same operon - provide additional information about the relationships between these gene-gene relationships. 
For example,  two genes that belong to the same operon are likely to have a similar set of regulators \cite{lawrence_shared_2002}, but knowing that two genes are members of a polycistronic transcript does little to inform the identity (strength, sign) of those regulators. 
Meta-information about the structure of gene regulatory networks, specifically which pairs of interactions are \textit{a priori} likely to be similar to one another, can provide a powerful set of constraints to improve network inference performance \cite{roy_arboretum:_2013, pierson_sharing_2015}. 
We present a general framework for gene regulatory network inference that incorporates this meta-information - termed fusion constraints - and apply the technique to the problem of simultaneous inference of regulatory networks in multiple species (\textit{B. subtilis} and \textit{B. anthracis}). 

We apply this algorithm to the problem of network inference in two distantly related biological organisms -- \textit{B. subtilis} and \textit{B. anthracis} -- and show that network recovery is improved through the introduction of fusion constraints between pairs of orthologous genes. 
Many previous methods for cross-species network inference operate on the conserved subset of orthologous genes \cite{dillman_comparative_2015}. 
This assumption may be appropriate with very closely related species, but could not be applied in this domain, where a large fraction (62\% and 67\%) of the \textit{B. subtilis} and \textit{B. anthracis} genomes do not have clear orthologs (and many orthologs have ambiguous many-to-many groupings). 
Our method, in contrast, can obtain improvements in network inference performance even when the conserved subset of genes is small. 
This approach is particularly interesting in light of the diversity of important model organisms used in modern biology. 
Different model systems provide different advantages and disadvantages for experimental design \cite{stolfi_genetic_2012}, but without a principled mechanism for combining data from multiple sources, it is difficult to fully leverage data obtained from even a slightly different model system. 
We further demonstrate the viability of fused L2 as a method for combining data from multiple experimental platforms, where fusion is between each identical regulator-gene pair. 
Because the algorithm we developed can accomodate constraints between arbitrary pairs of regulatory interactions, any biological prior representing information about expected regulatory similarity can be represented, even if the prior provides no information about the magnitude or direction of regulation. 
We demonstrate this flexibility through the novel incorporation of operon structure into the gene-regulatory network inference problem. 
In this application, fusion reflects the assumption that genes in the same operons have similar regulators \cite{lawrence_shared_2002}. 
The ability to incorporate multiple data sets describing related processes, as well as multiple data types, in a principled manner, helps us take advantage of the breadth of experimentation in biology to better learn the structure of gene regulation. 
We illustrate this by combining two different \textit{B. subtilis} datasets and show that fused L2 is an improvement over current approaches to combining data \cite{marbach_revealing_2010} because of our ability to exploit the statistical power that our expanded datasets afford us. 


Although it is important to take advantage of the similarities of related organisms for generating improved models of gene regulation, it is also critically important to understand how systems differ from one another. 
Our cross-species network inference method is premised on the assumption that orthologous genes have similar regulators. 
Existing approaches to the genome-wide testing of this assumption learn regulatory networks separately, then compare to identify conservation \cite{aytes_cross-species_2014}. 
Because network inference is typically underconstrained, fitting a network that describes a particular set of experimental observations involves sampling a single network from a large set of networks that fit the data equally (or almost equally) as well. As a result, the existence of a difference between corresponding regulatory interactions in a pair of experimentally derived networks is weak evidence that a difference truly does exist. 
Uncoupled global network inference algorithms are a very weak tool for uncovering evolutionary divergence. 
Our method explicitly favors recovering networks for which evolutionarily corresponding interactions are similar. 
As a result, the failure to obtain networks that confirm evolutionary conservation is stronger evidence that conservation does not exist; the next best network that does exhibit conservation must fit the data much worse to have overcome the bias built into the fusion constraints. 

We have described a method -- adaptive fusion -- that attempts to learn which fusion constraints should be relaxed while the network is being learned. 
This method is based on minimizing a saturating penalty function on fusion constraints, similar to a class of penalties that have been developed to minimise bias in regularized regression \cite{fan2001variable,zhang2010nearly}. 
The result of adaptive fusion is both a network and a new set of fusion constraints, describing the learned fusion weights (including which fusion constraints have been relaxed). 
For the multiple species case, relaxation of fusion constraints represents orthologs which do not share similar interactions presumably due to evolution of regulatory circuitry \cite{kellis_proof_2004}. %not sure what radid is
When jointly learning networks describing processes in different cell lines, this may identify interesting context-specific behavior. 
Genes may be fused together on the basis of similar binding sites or chromatin features, and the relaxing of the fusion penalty indicates divergence of gene function. 

Because our model shares its basic assumptions about the role of transcription factors in gene expression dynamics with models developed for single-species network inference, we are able to leverage techniques developed for the single-species estimation of transctiption factor activity \cite{fu_reconstructing_2011}. 
The performance gains of this additional step in the cross-species case are significant.
Our approaches -- fused L2 and adaptive fusion -- represent a very general framework for simultaneous network inference and the incorporation of structured biological priors. 
These priors -- incorporated into our method as fusion constraints -- allow the use of rich sources of biological knowledge, such as orthology and operon structure, which have informed experimental design, but are typically not incorporated into genome wide network inference algorithms. 
By accomodating the simultaneous inference of multiple related networks, we can improve network inference performance by allowing the efficient reuse of data from similar, but not necessarily identical, sources. 
A method for pooling data from multiple sources holds the promise of vastly expanding the quantity of data available for analysis, particularly in less commonly used model systems. 
At the same time these methods allow us to test our assumptions on how similar biological systems relate to one another, by allowing us to rule out conservation in a principled way, and at the genome-wide scale. 



%\nocite{*}
\bibliographystyle{plain}
\bibliography{paper1.bib}


\begin{figure}
\begin{center}
  \includegraphics[scale=0.45]{fig1.pdf}
  \caption{\label{fusion} \textbf{A.} Schematic representation of the the generation of fusion constraints from orthology mappings. Dashed arrows indicate potential regulatory interactions, while solid arrows denote orthology. We introduce fusion constraints for pairs of interactions for which both the regulator and regulated gene are orthologs of one another. 
  In this example, we would introduce a constraint between the $(A, B)$ and $(A', B')$ interactions and the $(A, C)$ and $(A', B')$ interactions. \textbf{B.} 
  In order to demonstrate the utility of fused network inference in combining data, we generate two networks with 10 TFs and 200 genes (75\% sparsity). Mean squared error of the inferred vs. true coefficient matrices for network 1 are plotted as a function of the number of conditions generated for species 1 (x-axis) and the number of conditions generated for species 2 (y-axis). 
  As expected, increasing the number of samples available for the species of interest improves network inference performance. 
  However, because we are fusing to data from a related species, similar gains are observed when increasing the amount of data available in this second species. 
  \textbf{C-F} Show the varying effects of fusion on simulated networks with different levels of conservation. We generate a series of networks with 20 TFs by 200 genes in two species, (50\% sparsity) while varying the fraction of gene orthologies in the simulated networks. For each network, we evaluated AUPR on one of the species for: all interactions (blue line), interactions with fusion constraints (green line), and interactions without fusion constraints (orange line). At every level of conservation, constrained interactions show the largest benefits of fusion, with the magnitude of the benefit growing with fraction of orthologous genes. 
  When the networks are highly conserved, however, even interactions that are not directly constrained through fusion are recovered more accurately as $\lambda_S$ increases.}
\end{center}
\end{figure}


\begin{figure}
\begin{center}
  \includegraphics[scale=0.45]{fig2.pdf}
  \caption{\label{syntheticgrid} This figure demonstrates the interaction between fusion weight ($\lambda_S$), the degree of orthology coverage of networks, and the degree of similarity between fused interactions. \textbf{A.} We generated a series of pairs of 10 TF by 200 gene networks (75\% sparsity) in two species. These networks had minimal fusion noise, so that pairs of interactions linking orthologs had nearly identical weight. We varied the fraction of genes with orthologs (y-axis) and the weight of fusion in network inference (x-axis), and measured performance as the mean-squared error of the true vs inferred network weights. 
  In order to more clearly visualize the varying effect of fusion, performance is plotted in relative units of the of the unfused MSE (left column) for each level of orthology. 
  This was necessary because each row represents a different pair of networks, generated with a different level of orthology, for which baseline performance varies. 
  Performance gains from fusion are, as expected, largest when the degree of orthology is large. However, even when the fraction of genes with orthologs is relatively small (top row), we observe gains from fusion. 
  When fused interactions are nearly identical, larger fusion weights always outperform smaller fusion weights. 
  \textbf{B.} Simulates the case where genes which are orthologs may have different regulatory weights. 
  We generated a series of networks as in \textbf{A.}, but with larger (7.5 $\times$) gaussian noise added the weights of fused interactions. 
  As in \textbf{A.}, benefits from fusion were observed at every level of gene orthology. However, unlike \textbf{A.}, there was an optimal intermediate value of $\lambda_S$ that traded off between the benefits of fusion and the cost of combining heterogenous data.}
\end{center}
\end{figure}

\begin{figure}
\begin{center}
  \includegraphics[scale=0.45]{fig3.pdf}
  \caption{\label{adapt-schematic} Adaptive fusion loss function (\textbf{A}) and derivative of loss function (\textbf{B}). 
  \textbf{A.} Adaptive fusion is a quadratic around the origin, begins to taper at $a/2$, and plateus at $a$. After the plateu, increasing the difference in interaction weight of fused interactions does not further affect the penalty incurred through fusion. As a result, interaction weights in this zone are effectively unfused from one another (the fusion penalty behaves like a constant). 
  \textbf{B.} Shows the derivative of the adaptive fusion penalty, which is used to implement adaptive fusion through local quadratic approximation. The adaptive fusion penalty is modified from SCAD (smoothly clipped absolute deviation) and MCP (minimax concave penalty) functions and like these penalties has a zero derivative far from the origin. }
\end{center}
\end{figure}

\begin{figure}
\begin{center}
  \includegraphics[scale=0.45]{fig4_2.pdf}
  \caption{\label{adaptivefusion} In order to evaluate the performance of adaptive fusion in unfusing interactions that have diverged through evolution, we performed a series of simulations inferring networks given a partially corrupted list of orthology mappings. 
  Networks were generated with 35 TFs by 200 genes, 60\% orthology coverage and 40\% false orthology coverage. \textbf{A.} We plot the interaction weights between pairs of fused interactions in network 1 (x-axis) and network 2 (y-axis) following network inference without fusion ($\lambda_S=0$). 
  Interactions that are generated from false orthologs are marked as red, while interactions generated from true orthologs are shown in green. 
  As expected, false fusion constraints give rise to uncorrelated weights (red dots). \textbf{B.} 
  When fit with fused-L2, fusion constraints give rise to very similar weights in the two species for 'true' and 'false' interactions. 
  \textbf{C.} Adaptive fusion run on the same network unfuses constraints for which the inferred weights are dissimilar beyond a certain point. 
  Here, unfused interactions are almost entirely interactions between false orthologs. \textbf{D-F} Show the distribution of the absolute value of the difference in inferred weight for interactions with true fusion constraints (green) and false fusion constraints (orange)}
\end{center}
\end{figure}

\begin{figure}
\begin{center}
  \includegraphics[scale=0.45]{fig5_2.pdf}
  \caption{\label{xspecies-real} a. Using optimal lamR and lamP values, we use 20-fold cross validation to learn B. subtilis network. 
  We comparedare performance when solving without fusion, and using L2 fusion with lamS = 1.0. Mean AUPR for lamS = 0 (unfused): 0.0298. 
  Mean AUPR for lamS = 1: 0.0388. b. We test adaptive fusion using the same setup, with the addition of false orthology information.
  We set a 30\% false potentialsitive rate, including 561 additional orthologs. We run adaptive fusion, setting the $a$ term equal to the value above which 40\% of constraints would unfuse, reflecting our belief that in addition to some of the known orthologs result in fusion constraints which should be relaxed. 
  Here we show the percentage of constraints relaxed, from constraints created from the false orthologs and the known orthologs. 
  We also show the distributions of differences in weights corresponding to fused constraints created from the false orthologs and the known orthologs, when networks are solved separately. }
\end{center}
\end{figure}


\begin{figure}
\begin{center}
  \includegraphics[scale=0.45]{fig6.pdf}
  \caption{\label{fusedl2-real} a. We use optimal lamR and lamP values, and solve for B. subtilis-1 and B. subtilis-2 networks using 10-fold cross validation. We fuse our original B. subtilis-1 dataset to another B. subtilis dataset, which we call B. subtilis-2, using orthology information, and evaluate performance of B. subtilis-1 using AUPR on gold standard. We compare L2 fusion with solving the networks separately without fusion, then rank combining as in Marbach et al., as well as solving B. subtilis on its own. b. We again use optimal lamR and lamP values, and solve for the B. subtilis network using 10-fold cross validation, and evaluate using AUPR on B. subtilis with gold standard. 
  Here, we fuse genes in the same operon group and compare L2 fusion performance using operons with unfused network inference.}
\end{center}
\end{figure}

\begin{figure}
\begin{center}
  \includegraphics[scale=0.45]{fig7.pdf}
  \caption{\label{tfa} We integrate transcription factor activity (TFA) into our network inference, and solve for B. subtilis-1 and B. subtilis-2 networks using 10-fold cross validation, using fused L2 with and without TFA. As in figure 6, we evaluate performance on B. subtilis-1 using AUPR on gold standard.}
\end{center}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[scale=.5,trim=0mm 0mm 0mm 0mm,clip]{party3.eps}
    \caption{\label{cartoon} Schematic representation of design matrix construction. Here, the circles and hexagons correspond to different species. 
    Bidirectional arrows represent orthology information and dotted arrows represent putative interactions between TFs and genes. 
    Rectangles represent matrices; because weights can be solved independently unless there exists fusion constraints between them, we identify related weights and construct matrix for solving. }
\end{figure}

\end{document}


