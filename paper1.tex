\documentclass[11pt]{article}
\usepackage{graphicx}
\usepackage[pdf]{pstricks}
%\usepackage{mathtools}
\usepackage{amssymb,amsmath}
\usepackage{textcomp}
\DeclareMathOperator*{\argmin}{arg\,min}

%\usepackage{subcaption}
%\usepackage{float}
\usepackage{setspace}
\usepackage{fullpage}
\usepackage[font=scriptsize]{caption}
%\usepackage{fullpage}
%\setcounter{secnumdepth}{1}
\begin{document}

\title{Fused regression for multi-source gene regulatory network inference}
\author{Kari Y. Lam, Zachary M. Westrick, Christian L. M\"{u}ller, Lionel Christiaen, Richard Bonneau}
\maketitle

\begin{abstract}
Understanding gene regulatory networks is critical to learning how cells regulate their behavior and respond to external stimuli. To this end, methods for global network inference have been developed and applied to a variety of species. However, most approaches consider the problem of network inference independently in each species, despite evidence that gene regulation is conserved even in distantly related species. We introduce a method for multi-source network inference that allows simultaneous estimation of gene regulatory networks in multiple species or biological processes through the incorporation of priors based on known gene relationships such as orthology. This approach improves network inference performance even when the orthology mapping in incomplete. We further refine this method with an algorithm that attempts to learn the true conserved subnetwork from a larger set of potentially conserved interactions. We demonstrate the utility of our method not only in cross species network inference, but also in merging data collected on different experimental platform and in incorporating binding similarity predictions.
\end{abstract}

\section{Introduction}
As the volume and variety of genome scale data have exploded, the goal of accurately modeling gene regulatory networks has become attainable \cite{bonneau_predictive_2007, ciofani_validated_2012, carro_transcriptional_2010}. Large-scale data collection efforts have contributed to the development of high quality networks which accurately recapitulate biological processes, but there remain many processes and organisms for which there does not exist adequate data. Furthermore, as new technologies are developed and some old ones are replaced, such as RNAseq and microarray, it becomes important to be able to combine data from multiple platforms, lest we lose valuable information from existing studies. The problem of inferring related -- but not necessarily identical -- structure from related -- but not identical -- data is ubiquitous in biology. Multi-source network inference has applications for learning multiple networks in multiple related species, for learning networks associated with distinct processes within the same species, and for learning networks based on heterogenous data sources.

Moreover, as it becomes possible to learn genome-wide regulatory networks, we can begin to compare and to test whether there is conservation of networks across species and biological processes. Our use of model organisms to study biological processes and diseases relevant to humans relies on the assumption of conservation; yet this has not been tested at the genome scale. 

We present two methods for network inference based on linear estimates of gene expression dynamics, extending existing linear dynamical-systems methods for network inference \cite{bonneau_predictive_2007, arrieta-ortiz_experimentally_2015}. The core of both methods is the observation that biological information about the relatedness of genes can be used to constrain which network coefficients should be similar to one another in a multi-source network inference problem (ie orthologous TFs should regulate orthologous genes), and that these constraints can be efficiently represented as penalties in a least-squares regression problem. Our approach uses predictions of similarity of putative interactions, to improve our ability to accurately describe TF-gene relationships on a genome-wide scale.  

Our first method -- fused ridge -- uses an L2 penalty on the differences between a priori similar interactions, and is useful where the relationships between networks (similarity of genes between data sets) is reliable. In the case where both networks contain an identical set of genes and TFs, this approach can be thought of as parametrically interpolating between treating the data sources separately and combining them together. However, our method allows useful pooling of data even when the overlap between genes is incomplete. Our second method -- adaptive fusion -- uses a non-concave saturating fusion penalty to simultaneously infer the constrained networks and to learn which constraints should be relaxed (ie which parts of the network are genuinely different). With this approach, we seek to test the hypothesis of conservation of interactions across networks.

In the case of multiple species, there has been a great deal of work showing that functional conservation exists in gene regulatory networks even across large evolutionary distance \cite{satou2006gene, hinman2009evolution,tanay2005conservation,erwin2009evolution}. In our fused L2 approach, we make the assumption that for closely related species, if a pair of TFs is orthologous to one another, then their regulatory effects on a pair of orthologous genes should be similar. These orthology relationships form the basis of a set of constraints which favor -- but do not require -- networks in which orthologous transctiption factors regulate orthologous genes. As a result, data in one species can improve network inference performance in another species  (and vice versa). This general framework for multi-species network inference can be extended to an arbitrary number of distinct organisms, each contributing data with only partially overlapping sets of genes. This is an advantage over existing approaches to multi-species network inference, which infer only a sub-network for which orthologs exist in every species \cite{joshi_multi-species_2015}. This approach of introducting constraints on the similarity between specific regulatory interactions can be extended beyond the case of multi-species network-inference from orthology; any biological prior on similarity can be used in place of orthology. For example, we can introduce constraints that favor genes in the same operon or having similar binding sites, having similar regulators.

Existing multi species approaches often use orthology as a proxy for functional conservation \cite{penfold_inferring_2015, joshi_multi-species_2015, kashima_simultaneous_2009, zhang2010nearly}, or attempt to learn functional similarity via expression data \cite{gholami_cross-species_2010}. Orthology -- the measure of gene similarity we use -- can be approximated using readily identifiable sequence similarity. Sequence similarity is often a useful predictor of functional similarity \cite{wilson_assessing_2000}. In multi-species network inference, our fused L2 approach minimizes a cost function that strives to simultaneously fit expression data in each species and produce networks that are consistent with evolutionary constraints created using orthology. However, we recognize that some genes may have taken on different functions and therefore may have new regulatory interactions. Gene duplications and neofunctionalization in multi-species network inference \cite{eisen_phylogenomics:_1998}, and changes in chromatin configuration in multi-cell line network inference \cite{li_role_2007}, are cases where assumptions about functional conservation may not hold. 

Understanding which interactions are functionally dissimilar is of direct biological interest, but existing approaches to network inference are unable to effectively rule out conservation. Observing a large difference in the weights of regulatory interactions obtained though independent inference of multiple networks is the best evidence against conservation available with existing network inference techniques. This evidence is very weak, however; because network inference is typically underconstrainted \cite{marbach_revealing_2010-1}, there could be a different set of networks for which conservation does hold, and which fit the data almost as well. We propose, with our adaptive fusion, an approach where network inference occurs simultaneously with the evaluation of conservation, to gather stronger evidence of divergence. 

We approach this problem by introducing a saturating penalty function based on work in statistics to develop unbiased regularization penalties for regression \cite{zhang2010nearly, fan2001variable}. The main difference between the L2 fusion approach and this adaptive fusion approach occurs when the difference between presumed analogous interactions is large despite the fusion penalty: we assume that large differences represent evidence that gene functions have diverged and represent this, in adaptive fusion, with a relaxation of the fusion penalty. The resulting cost function is non-convex and difficult to optimize; however, we can approximate its solution and obtain deeper insight into functional similarity than is available through orthology or the comparison of separately learned networks. 

We test the ability of fused L2 and adaptive fusion to improve network recovery on both synthetic data and \textit{Bacillus subtilis} and \textit{Bacillus anthracis}, showing the applicability of our method in combining different datasets, and leveraging similarity across organisms as well as within a network in order to improve network inference. We explore the circumstances under which each approach is optimal, and evaluate the robustness of adaptive fusion to incorrect orthology, simulating the biologically relevant case of neofunctionalization. 

\section{Methods}
Although our approach is generalizable to a wide variety of multi-source network inference problems, we begin with the concrete example of network inference in two related species. Our approach to multi-species network inference is based on the hypothesis that gene regulation in related species is governed by similar but not necessarily identical gene regulatory networks, due to conservation of function through evolution. We represent conservation of network function by introducing constraints into the objective function for network inference that penalize differences between the weights of regulatory interactions believed to be a priori similar. These constraints favor the generation of similar networks for related species, and in the generally under-constrained regime of network inference can improve the accuracy of network recovery. We then go on to introduce a method to test the assumption of conserved network structure, and to relax the associated constraints on pairs of interactions for which data does not support conservation.

\subsection{\textit{B. subtilis} and \textit{B. anthracis} data and orthology}
We used a dataset collected for PY79, a derivative of strain 168, available on GEO with accession number GSE67023, and a dataset using BSB1, another derivative of strain 168, available at GEO with accession number GSE27219. We used two datasets for \texti{B. anthracis}, transcription profiling during iron starvation (E-MEXP-2272 on ArrayExpress), and time series over the life cycle (E-MEXP-788 on ArayExpress). We ran Inparanoid to obtain orthology mapping for \textit{B. subtilis} and \textit{B. anthracis} \cite{ostlund_inparanoid_2010}

\subsection{Gene regulatory network}
We model the transcription rate of each gene as a weighted sum of transcription factor (TF) expression, and seek to identify the identities and regulatory weights of these TFs. This formulation matches that of the existing Inferelator algorithm, which models gene expression with linear differential equations \cite{bonneau_inferelator:_2006-1}. Our primary data for learning gene regulatory networks is expression data, consisting of time-series and steady state experiments. We use time-series data to approximate the rate of change of expression, and treat steady-state experiments as having reached equilibrium (constant expression). The rate at which $x_{i}$, the observed mRNA expression of gene $i$, changes, is governed by degradation of existing transcripts with rate $\alpha$ plus a linear combination of transcription factor (TF) expressions. 
\begin{equation}
\frac{\mathrm d}{\mathrm d t} x_i = -\alpha_{i}x_{i} + \sum \beta_{i,j}x_{j}
\end{equation}
where $\beta_{i,j}$ represents the weight of TF $j$ on gene $i$, and $\alpha$ is the decay rate of gene $i$. We fix the decay rate $\alpha$ for all genes, and set it assuming a time-constant of 10 minutes \cite{hambraeus_genome-wide_2003, selinger_global_2003}, as in \cite{greenfield_robust_2013}. Let $x_i(t)$ be the expression of gene $i$ at time $t$. Given time-series data on the expression of gene $i$ at timepoints $t_k$ and $t_{k+1}$, we can approximate the rate of change of $x_i$ as $x_i'(t_k)=\frac{x_i(t_{k+1})-x_i(t_k)}{t_{k+1}-t_k}$. We treat steady-state data as having a derivative of zero. This gives us, for each gene $i$ and time $t_{k}$ an equation

\begin{equation}
\frac{x_i(t_{k+1})-x_i(t_k)}{t_{k+1}-t_k} + \alpha_{i}x_{i}(t_k)= \sum \beta_{i,j}x_{j}(t_k)
\end{equation}
for time series
\begin{equation}
0 = \sum \beta_{i,j}x_{j}(t_k)
\end{equation}
for steady state
\noindent We can summarize these equations in matrix form as
\begin{equation}
Y = X \beta 
\end{equation}

We are interested in learning $\beta$, the matrix representation of the gene regulatory network, where the weight in a given position represents the regulatory weight of a TF on a gene. Positive weights represent activation, negative weights represent repression, and 0 weights represent the absence of an interaction. 

\noindent The matrix $\beta$ can be solved using linear regression. Because there are typically far fewer conditions than possible regressors (TFs), we introduce a ridge regularization constraint with weight $\lambda_R$ and solve
\begin{equation}
\argmin_\beta\vert \vert X\beta - Y_2 \vert \vert ^2 + \lambda_R \vert \vert \beta \vert \vert ^2
\end{equation}
This is similar to the formulation used in the Inferelator algorithm, which we extend to the case of simultaneously inferring multiple networks. 
\subsection{Estimating transcription factor activity and using TFA as regressors}
When there exists a set of prior known interactions, we are able to estimate transcription factor activity (TFA) using network component analysis \cite{liao2003network}, as in \cite{arrieta-ortiz_experimentally_2015, fu_reconstructing_2011}, and use TFA as explanatory variables instead of transcription factor expression. 

\subsection{Fused gene regulatory networks}

Information about the conserved structure of gene regulation is introduced through the incorporation of constraints into the above regression formulation. These constraints penalize differences between interaction weights in the networks of multiple species that are expected to be similar based on prior biological knowledge. We can then solve the penalized regression problems simultaneously, in order to obtain a GRN for each species. Consider the case of organisms $A$ and $B$, governed by GRNs $\beta^A$ and $\beta^B$ (the following approach applies equally well to more than two species but for simplicity we continue with the case of two species). If TF $g^A$ in organism $A$ and TF $h^B$ in organism $B$ are orthologs, and gene $k^A$ and $l^B$ are orthologs, then we expect that the $g^A \rightarrow k^A$ interaction weight should be similar to the $h^B \rightarrow l^B$ interaction weight, and we introduce a fusion constraint between these analogous interactions. In terms of the above regression formulation, we expect that $\beta^A_{g,k} \approx \beta^B_{h,l}$, and include a penalty term $p_{\lambda_S}(\beta^A_{g,k} - \beta^B_{h,l})$ in the quantity being minimized in order to encourage similarity. The function $p_{\lambda_S}(x)$ controls the shape of the relationship between weight dissimilarity and penalty, while parameter $\lambda_S$ controls the overall scaling of the penalization of differences between fused coefficients. $\lambda_S$ controls the tradeoff between fitting the expression data alone and producing a set of networks that conform to evolutionary prior knowledge. This gives us the final equation to be minimized 
\begin{equation}
%\argmin_{(\beta^A, \beta^B)} \displaystyle\sum_{S \in (A, B)} \vert \vert X^S\beta^S - Y^S \vert \vert ^2 + \lambda_R \vert \vert \beta^S \vert \vert ^2 + \displaystyle \sum_{\beta^{S_1}_{g,k} \approx \beta^{S_2}_{h,l}} p_{\lambda_S}(\beta^{S_1}_{g,k} - \beta^{S_2}_{h,l})
\argmin_{\beta^S} \displaystyle\sum_{S \in \text{species}} \vert \vert X^S\beta^S - Y^S \vert \vert ^2 + \lambda_R \vert \vert \beta^S \vert \vert ^2 + \displaystyle \sum_{\substack{(g,h) \in orth,\\
 (h,l) \in orth}}x p_{\lambda_S}(\beta^{S_1}_{g,k} - \beta^{S_2}_{h,l})
\end{equation}

where the second sum is over pairs of interactions with fusion constraints. In the fused L2 algorithm we develop, the penalty function is equal to the L2 norm of the difference in regulatory weight of fused coefficients. That is, $p_{\lambda_S}(x)=x^2$. The overall objective function for network inference is then:

\begin{equation}
\argmin_{\beta^S} \displaystyle\sum_{S \in \text{species}} \vert \vert X^S\beta^S - Y^S \vert \vert ^2 + \lambda_R \vert \vert \beta^S \vert \vert ^2 + \displaystyle \lambda_S \sum_{\substack{(g,h) \in orth,\\
 (h,l) \in orth}} \vert \vert (\beta^{S_1}_{g,k} - \beta^{S_2}_{h,l}) \vert \vert ^2
\end{equation}

Because every component of the objective function is an L2 norm, the entire problem is convex, and can be solved through linear regression with a suitable design matrix. %The regulators of a pair of genes can be solved independently as long as the pair is not linked by fusion constraints, or a chain of fusion constraints; thus the problem of cross-species GRN inference decomposes into a large number of manageable regression problems as long as the orthology mappings are sparse.

In order to better understand the behavior of this objective function, consider the case where there is a one-to-one orthology between the species being considered (ie different cell-lines of the same organism). The choice of $\lambda_S$ allows one to interpolate between fitting each network independently ($\lambda_S=0$) and pooling data together as if it came from one source ($\lambda_S=\inf$). Part of the appeal of the approach, however, is that it allows pooling of data even when there is incomplete orthology. By introducing constraints on the similarity of individual interactions, rather than on the networks as a whole \cite{liu2011temporal}, we can pool some information across species even when an arbitrarily small fraction of genes have orthologs. This is particularly useful when dealing with a large number of species; pairwise orthologies may be nearly complete even when the number of genes present in every organism is small. 

\subsection{Statistical approach and background}
Most network inference problems have more predictors than experimental samples ($p >> N$). Many methods have been proposed for penalized regression, such as ridge regression \cite{hoerl_ridge_1970}, and applied to genomic data \cite{waldron_optimized_2011, li_network-constrained_2008}. In our application, we consider the case where related outputs (genes) are likely to be affected by common inputs (transcription factors). Fusion has been proposed as a method for utilizing correlation information from data by penalizing pairwise differences of coefficients \cite{Daye2009,Price2014}. Approaches using fusion combine statistical strength across the multiple regression tasks by introducing regularization functions reflecting prior knowledge on output structure representing how outputs are related \cite{kim_tree-guided_2012,Land1997,Chen2010,Petry2011,Hebiri2011}. Price et al. and Bilgrau et al. use a fused ridge estimator for jointly estimating multiple inverse covariance matrices \cite{Price2014a,Bilgrau2015}; we take a similar approach, adding an fused L2 penalty to our ridge regression to incorporate prior knowledge about relationships between input-output pairs. Sohn et al. attempt to simultaneously learn the regression coefficients and the output structure \cite{sohn_joint_2012}. We also take a simultaneous approach, where we apply a penalty function bounded by a constant to produce unbiased estimators for large coefficients, combined with an L2 penalty, similar to SCAD-L2 \cite{Zeng2012}. This approach allows us to simultaneously learn the regression coefficients and evaluate the validity of our prior information. 

\subsection{Solving fused L2 problems using augmented matrices}
We begin with the problem of constructing a design matrix to solve a fused L2 regression problem with a single response variable, because problems with multiple response variables and with multiple data sources can be converted into this form through vectorization. We then go on to show that, although the vectorized solution involves solving an impractically large system of equations, under typical biological conditions the structure of constraints allow the problem to be broken up into many smaller subproblems. 

We use the fact that ridge constraints can be incorporated into a least-squares regression problem by appending a scaled identity matrix to the design matrix, and a corresponding number of zeros to the response vector. Similarly, a fusion constraint $\lambda_S (\beta_{i} - \beta{j})^2$ can be incorporated into a least-squares regression problem by appending a row containing $\sqrt{lambda_S}$ in the $i$th position, $-\sqrt{lambda_S}$ in the $j$th position, and $0$s elsewhere to the design matrix, and zero to the response vector. 

In order to convert an optimization over multiple response variables (indexed by $i$) and multiple sources (indexed by $j$) with design matrices $X^{S_j}$ and response variables $y_i^{S_j}$ into an optimization with a single source and response variable, we vectorize as follows. Let $G$ be a set containing $(i,j)$ for each of the data sources and response variables currently being optimized. We construct the matrix $A$ by diagonally concatenating each of $X^{S_j}$ (with the remaining entries 0) and vertically concatenating each of $y_j^{S_j}$. We then solve
%Specifically, if $Y \in R^{N \times M}$ then we form $A =$ diagonally concatenate $X$, $M$ times (with the remaining entries 0),
%$y =$ vertically concatenate the columns of $Y$. We solve 

$$\underset{W}{min} ||AW - y||_2^{~2}$$

%We can then define $W_{i,j} = \beta_{(j-1) \times N + i, (j-1) \times M + j}$ which is the desired form.
This is equivalent to the original problem due to the block structure of matrix multiplication. In an ordinary regression problem each response variable can be solved independently as a large number of small regression problems. However, in fused regression, we append additional rows to the design matrix $A$ that link entries of $W$ associated with different response variables. As a result, these linked response variables must be solved simultaneously through vectorization. Two response variables are linked by a fusion constraint if any of the regulatory weights affecting those genes are linked by a fusion constraint. Two response variables must be solved simultaneously if there is any chain of linked response variables connecting them. However, every other response variable can be solved separately. In biological terms, the regulators of two genes (whether in the same species, or different species) must be solved together if there is a fusion constraint linking those genes' regulators, or if there is a chain of such constraints. This is important because vectorization produces a design matrix with a number of rows and columns equal to the sum of the number of rows and columns of the design matrices associated with each of the response variables (genes) being solved for. If the networks for a large number of genes are solved simultaneously, the system of equations can quickly become intractible to solve. 

In order to avoid this difficulty, we use depth-first search to identify linked columns of each TF expression matrix $Y^{S_j}$, then forming design and response matrices through vectorization. We can then incorporate fusion constraints as in the case of single-source single response-variable fused regression. In most cases, we have found the direct solve using augmented matrices to be adequate. This is because the structure of orthology tends to be sparse, so only a small number of genes must be solved at once. However, in the general case of $c_i$ response variables from each of $i \in \text{species}$ data sources the design matrix to be solved is of size $\displaystyle \sum_{c_i} rows(X^{S_i}) \times \displaystyle \sum_{c_i} cols(X^{S_i})$ plus a relatively small number of rows representing fusion constraints. Because the scaling of this algorithm has a complicated depence on the constraint structure used, a general description of its runtime is difficult. However, in the case of multi-species network inference with one-to-one orthology, the network associated with each pair of orthologous genes requires solving a linear system with approximately twice as many observations and unknowns as the single species case. Linear systems of this size can be solved quickly using standard techniques. When the number of genes linked by fusion constraints becomes large, however, the augmented design matrix approach becomes impractical.


%where the $j$s refer to transcription factors. In subproblem 1, $j_1$ regulates gene $g$; $j_1$ is orthologous to $j_2$, a transcription factor of subproblem 2, which regulates $h$, a gene which is orthologous to gene $g$. There exists a chain because ($j_1$, $g$) is a TF, gene pair which is fused with ($j_2$, $h$), which is fused to ($j_3$, $k$).
%We use depth-first search to identify linked columns of $Y$, and then solve the fused regression problem directly by vectorizing those columns.
%In order to incorporate the fusion penalty, we append to the resulting design matrix one row \emph{per connected constraint}, which contains $\lambda_S$ in the column associated with $Y_g,i,j,$ and $-\lambda_S$ to the column associated with $Y_h, i',j'$ for constraint $(Y_g,i,j,Y_h,i',j')$. Call this resulting matrix $X_P$.
%The vector $Y$ is augmented by appending an appropriate number of zeros to produce $Y_P$. As a result, each entry in the output of $X_P b$ in the columns associated with each constraint contain $\lambda_S(b_{i,j} - b_{i',j'})$.
%These entries each contribute  $\lambda_S||b_{i,j} - b_{i',j'}||^{2}$ to the squared error $||X_Pb - Y_P||_2^{~2}$

%In the context of regression for GRN inference with multiple cell sources, each gene $j$ from source $1$ has constraints $\forall_{i \in \{TFs\}} (1, i, j, 2, i’, j’)$ where $i',j'$ are the same gene in a different cell line.
%As a result, each gene has only one constraint and the chain has length $L=2$.
%In general, however, solving the fused regression problem directly, even after factoring constraints, involves at least one inversion of an $L\sum_{i=0}^S K_i \times L \sum_{i=0}^S K_i$ matrix, taking $O((L\sum_{i=0}^S K_i)^3)$.
%In general, however, solving the fused regression problem directly, even after factoring constraints, involves at least one inversion of an $p\sum_{i=0}^S K_i \times p \sum_{i=0}^S K_i$ matrix where $p$ is the size of a column subset such that there is a constraint chain $L$ linking an element of each column to an element in every other column in that subset, taking $O((p\sum_{i=0}^S K_i)^3)$.
%Although the sparse structure of $X_P$ makes this somewhat more tractable, it is still impractical for large $L$.

\subsection{Iterative solver}

When the number of genes in each fusion constraints is relatively small, the augmented design matrix approach we have described has the advantage of being efficiently solvable with a closed form solution. However, in some cases the augmented system of equations may be too large to solve efficiently with standard methods. To address this limitation, we developed an iterative solver that uses coordinate-wise descent to solve for solutions corresponding to a sequence of values of fusion penalty weights; since our fused L2 method uses a convex and differentiable penalty function, this approach converges to a global minimizer. Although less efficient than the augmented design matrix approach we developed, the iterative solver has the advantage of computing a solution path for $\lambda_S$.

On each iteration $t$ the iterative solver computes


\begin{equation}
\text{argmin}_{\beta^{S_i(t)}, \beta^{S_j(t)}} \displaystyle\sum_{S_i, S_j \in \text{species}} ||X^{S_i}\beta^{S_i}(t) - Y^{S_i}||^2 + \lambda_R||\beta^{S_i}(t)||^2 + \displaystyle \sum_{\beta_{g,k}^{S_i} \approx \beta_{h,l}^{S_j}} \lambda_S(\beta^{S_i}_{g,k}(t) - \beta_{h,l}^{S_j}(t-1)^2)
\end{equation}
Note that this is almost identical to equation 5, but now the network $\beta$ is a function of the iteration number $t$. On each step, the we compute $\beta$s that minimize a penalized cost function where the fusion penalty encourages similarity of a pair of parameters, using the previous iteration's solution. This process is iterated until the estimated $\beta$s converge. Because each iteration reduces the error between $\beta(t)$ and $\beta(t-1)$, and because $\beta(t) = \beta(t-1)$ is the globally optimal solution, this process must eventually converge to the same network as (cite 5). Although we have not produced bounds on the convergence rate, in practice a small number of iterations are necessary.

The ierative solver is used for multi-source regression problems with complex orthology/similarity mappings, and also for solving the regularization path in order to pick regularization and fusion penalty weights. 

\subsection{Fusion and regularization path}
The iterative solver requires an initial guess $\beta^{S_i}(0)$ for each species $S_i$. When the initial guess is close to the final solution, a small number of iterations are necessary. Because a small change in $\lambda_S$ will tend to produce a small change in the network, solving for the $\lambda_S+\epsilon$ network given $\beta$s initialized to the $\lambda_S$ network requires a small number of iterations. As a consequence, the entire solution path corresponding to a large number of values of $\lambda_S= \lambda_S_1, \lambda_S_2, ..., \lambda_S_{max}$ can be solved efficiently by using the solution of each network as the initial guess for the next. 

We use Tibshirani's cyclical coordinate descent algorithms from the 'glmnet' package \cite{friedman_regularization_2010} to compute a ridge regularization path. As jointly optimizing $\lambda_R$ and $\lambda_S$ is computationally prohibitive, we opted to optimize the parameters separately. First, we use glmnet to compute the regularization path for the ridge penalty, and given a range of $\lambda_R$ values, we fit models for each $\lambda_R$. We use cross validation to select the optimal parameter, the $\lambda_R$ value which minimizes the error of prediction on the leave out set. Following selection of $\lambda_R$, we search for optimal $\lambda_S$ again using cross validation. Note that both parameters are chosen without reference to the gold standard, which is used in a separate evaluation of network quality. 

%\subsection{Equivalent prior}
%Our L2 fusion penalty is equivalent to assuming a Gaussian prior with variance proportional to $\frac{1}{\lambda_S}$ on differences in parameters with fusion constraints. Combined with the regularization constraints, this forms a multivariate Gaussian prior on weights in both networks. When using our method on systems with incomplete orthology mapping, this results in different prior probability distributions for those parameters with fusion constraints and those without. We adjust for this by solving for a constant to multiply fused interactions by to equalize the volumes of the prior distributions. The intent of this adjustment is to ensure that constrained interactions are not on average more highly penalized, which may tend to drive their weight towards zero, causing them to be excluded from the network. 

\subsection{Adaptive fusion}
Fusion constraints are intended to penalize dissimilarity between interactions thought to be analogous based on some a priori knowledge. For example, orthology can be used to predict which interactions will be similar across species. Because fusion constraints are L2, interaction weights which differ from each other by a large amount are excessively penalized, which effectively ensures that fused interactions are assigned similar weights. This may be inappropriate for interactions which are identified based on orthology as being analogous, but which are no longer similar due to evolutionary changes. We propose that a saturating penalty may be useful for dealing with uncertainty about which interactions are conserved. 

With a saturating fusion penalty, fused interactions which appear to be very different based on expression data are allowed to unfuse from one another. A closely related problem has been studied in the context of LASSO regularization, where it was shown by Fan and Li that using a saturating penalty retains many of LASSO's desireable properties while removing its bias towards 0 \cite{fan2001variable}. They further showed that, although the resulting loss-function is nonconvex, good results can be obtained with a local quadratic approximation of gradient descent. Several saturating penalties, such as SCAD \cite{fan2001variable} and MCP \cite{zhang2010nearly}, have been discussed in the context of sparse regression. We introduce a modified form of MCP to the problem of penalizing differences between fused coefficients. The principle difference between the penalty we adopt and SCAD/MCP is that both of these penalties are L1 like at the origin, producing sparse solutions. Some network inference approaches use L1 penalties to produce sparse networks, on the basis that biological networks are thought to be sparse. However, since we are penalizing differences in interaction weights, rather than the weights themselves, there's no reason to assume that most differences will be exactly zero. 

We use a penalty on the difference between fused coefficients $\theta$ which is L2 like at the origin, begins to level out at $\theta = \frac{a}{2}$, and saturates at $\theta = a$. Written in terms of its derivative, the penalty $p'_{\lambda, a}$

\begin{equation}
p'_{\lambda,a}(\theta) = \left\{
    \begin{array}{lr}
    2\lambda\theta & \text{if } \theta \leq \lambda\\
    \text{max}(\lambda_S(a-\theta),0) & \text{if } \theta > {a \over 2}
    \end{array}
    \right.
\end{equation}

%We also implement MCP:

%\begin{equation}
%p_{\lambda,\gamma}(\theta) = \left\{
%    \begin{array}{lr}
%    \lambda\theta^2-{ \theta^2 \over 2\gamma} & \text{if } \theta \leq \gamma\lambda\\
%    {1 \over 2}\gamma\lambda^2 & \text{if } \theta > \gamma\lambda
%    \end{array}
%    \right. 
%\end{equation}

%With derivative

%\begin{equation}
%p'_{\lambda,\gamma}(\theta) = \left\{
%    \begin{array}{lr}
%    2\lambda\theta - {\theta \over \gamma} & \text{if } \theta \leq \gamma\lambda\\
%    0 & \text{if } \theta > \gamma\lambda
%    \end{array}
%    \right.
%\end{equation}
    
As in \cite{fan2001variable}, we use solve using iterative local quadratic approximation. 

Specifically, $\beta^S(t)$ is the network on iteration $t$. 

For each fused $B^{S_1}_{g,k} \approx B^{S_2}_{h,l}$ we define:

\begin{equation} 
\theta(0)=0
\end{equation}
\begin{equation}
\theta(t) = \vert B^{S_1}_{g,k} - B^{S_2}_{h,l} \vert
\end{equation}

and introduce a fusion constraint $\lambda = \frac{p'(\theta(t))}{2\theta(t)} $

$\beta^S(t+1)$ is obtained by fitting the ridge-fused model with fusion constraints given by the above $\lambda_S$. This is nice because all our penalties can be treated as L2 and therefore retain the properties of ridge regression. 

Our adaptive penalty function introduces, in addition to regularization and fusion penalty weights $\lambda_R$ and $\lambda_S$, an unknown parameter $a$. We could employ grid search using cross-validation to searach for the best parameters, but for many data sets, this can be computationally expensive. Moreover, we are primarily interested in using this saturating penalty as a way of testing the hypothesis that conservation in GRNs can be predicted based off of known similarities between genes. Therefore, we implement a way of selecting $a$ to be equal to a certain percentile of the distribution of differences in fused interaction weights from the networks fit without fusion. This choice represents the user's hypothesis for the fraction of both networks that have unrelated function, and should therefore be unfused. 

%\subsection{Model selection}
%We can define a leave-out set of priors and choose parameters based on cross-validated AUPR on the leave-out set. 


\subsection{Simulated data}
We generate simulated data to evaluate the ability of our fused L2 approach to learn the true network and to show that sharing information between similar but not identical data sources results in more accurate network recovery. Because the purpose of adaptive fusion is to learn the structure of conservation while also learning networks, using simulated data allows us to test the method relative to a known gold standard for network conservation. 
Our simulations are based on the model $Y=X\beta+\sigma \epsilon$ where $\epsilion \sim N(0,1)$. Each data set consists of a training set and test set. 

Generation of simulated data begins with the production of random orthology mappings. We produce a one-to-one orthology by pairing random genes until a specified fraction have been assigned orthologs. This process is carried out separately for TFs and non-TF genes, so that TFs and non-TF genes are never assigned to be orthologous. We then produce a pair of random networks ($B^1$ and $B^2$) as follows. For each unfilled entry in $B^1$ or $B^2$, we enumerate the set $C$ consisting of the entry along with every entry in either matrix to which it is fused. With probability equal to the sparsity rate we assign every entry in $C$ to be 0, otherwise we sample a value $v \sim \mathcal{N}(0,1)$ and independently assign each entry in $C$ to $v + \mathcal{N}(0, \sigma_f^2)$. $\sigma_f$ is a parameter that controls the distribution of differences in the values of fused coefficients, so that the nonzero coefficients of $B^1, B^2$ are distributed as $\mathcal{N}(0, 1 + \sigma_f^2)$.

Given a network $B$, we generate $N$ samples of gene expressions at each of two timepoints. The condition by gene expression matrix for timepoint one, $Y_{T1}$, is sampled randomly from a multivariate Gaussian distribution with identity covariance matrix. $X_{T1}$ is the TF expression sub-matrix of $Y_{T1}$, and consists of columns of $Y_{T1}$ that correspond to TFs. Treating the decay rate as 0, the gene expression matrix at timepoint two, $Y_{T2}$ is sampled as $Y_{T2} = Y_{T1} + BX_{T1}$. This process is carried out separately for each network. 

Following generation of simulated data, we may introduce error into the orthology mapping. This can take the form of discarding a specified fraction of true orthologies (governed by a false-negative rate), by introducing random false orthologies (governed by a false-positive rate), or by adding Gaussian noise so that fused interactions are not identical. For convenience, the false-positive rate is specified in units of the number of true orthologs, and not the number of possible orthologs. 

For the purposes of evaluating simulated network recovery, we define a gold standard network as the support of the beta matrices. Priors used in network inference are interactions present in the gold standard. The list of priors can be be manipulated to include false positives and false negatives as with ortholog mapping. 

\subsection{Beta scaling}
In previous work, betas were rescaled as to form a matrix of confidence scores $S$ as follows
\begin{equation}
S_{i,j} = \frac{\sigma^2_{\text{full model for }y_j}}{\sigma^2_{\text{full model for }y_j \text{ without predictor }i}}
\end{equation}
Computing residuals with respect to the data alone would disregard information gained through fusion. Instead, we used an approximation
\begin{equation}
S_{i,j} = \frac{\sigma^2_{\text{full model for }y_j}}{\sigma^2_{\text{full model for }y_j} + B_{i,j}^2 \times var(TF_j)}
\end{equation}
When the residual is uncorrelated with the prediction, then removing regressor $i$ with weight $B_{i,j}^2$ from the model of $j$ will increase the residual by $B_{i,j}^2$ times the variance of regressor $i$. In the case of regularized regression, the regressor and residual need not be uncorrelated, so the approximation will not hold exactly. This scaling is similar to rescaling according to variance explained relative to an augmented design matrix that includes fusion constraints. The intuition for scaling that a large $B_{i,j}$ may be inferred because of overfitting with a TF $i$ varies little across the available data, or because the regulatory weight is strong. Only in the latter case is a large weight suggestive of a true regulatory interaction.

\section{Results}
We tested the ability of fused regression to improve network inference performance, as well as the ability of adaptive fusion to learn the conservation of gene interactions, using both synthetic networks and real data. For the synthetic data, we generated random pairs of networks in which orthologous genes have similar regulatory interactions, then sampled gene expression from these networks, which we used to derive networks for comparison with the true networks. For real data, we computed recovery of a known gold standard in \textit{Bacillus subtilis}. We measured network inference performance with the area under the precision recall curve (AUPR). 

\subsection{Using fused regression to learn related networks}
It is known that network recovery improves with additional data \cite{bar-joseph_computational_2003}. Additional data is not always readily available; but often there is an abundance of related data, and we reason that we should be able to use data describing similar processes. Using related data for network inference allows us to borrow statistical power from other sources, effectively increasing the sample size and boosting the sensitivity and specificity of learned interactions. We use the assumption that similar genes have similar regulatory interactions, and share information about putatively conserved interactions. We created synthetic networks to approximate two related biological processes, then evaluated performance of our fused L2 regression, which learns the networks simultaneously, sharing information about related interactions (Figure 1b). We compared recovery of the 10 TF by 200 gene networks, using fused L2 versus learning networks separately. We varied the amounts of simulated expression data made available to the solver. When the amount of data from species two was held constant, increasing the amount of data available for learning the network for species one resulted in a more accurate network, as expected. When we increased the amount of data from species two, we obtained performance gains on network one using fused L2 regression, showing our ability to improve network inference on one dataset by sharing data from a related dataset. 

The decision of what other sources to draw from is an important one; at one extreme is combining unrelated data, and at the other is resampling from the same experiments. We simulated this spectrum by creating pairs of networks and varying the similarity between networks. The main factors governing similarity between our generated networks was the extent (and accuracy) of the orthology mapping, and the variability between analogous, or conserved, interactions (in other words, how well conserved the conserved subnetwork was). We conducted a series of simulations to assess the effect of increasing orthology coverage on networks. In order to determine the effect of the size of the orthology mapping on network inference performance, we simulated a series of 20 TFs by 200 genes networks at several values of percent orthology coverage. 

As expected, when the conserved subgraph was very similar - when the interactions in the conserved subnetwork were nearly identical, simulating the case of closely related organisms or similar processes (Figure 2A) - increasing the weight of the fusion penalty $\lambda_S$ improved network recovery. As the size of the conserved subgraph increased, using a greater weight on the fusion penalty was beneficial.

To simulate the case of distantly related organisms, we created networks where conserved interactions were drawn from high variance distribution (Figure 2B). When the conservation iss weak - when the interactions in the conserved subnetwork are nearly as different across species as randomly chosen interactions - performance may not continue to improve by increasing the fusion weight. We showed that even for networks where the conserved subgraph was weakly conserved, there exists a 'sweet spot' where fusion regression improves network recovery. 


\subsection{Fused regression improves performance on both the constrained and non-constrained parts of the network}
Our method learns related networks simultaneously, using predictions about conservation of TF-gene interactions to share information between sources. Our approach is useful for learning networks from similar sources such as different cell-lines from the same species, where there exists a one-to-one mapping of genes, as well as datasets where the orthology mapping does not span all the genes. This can occur when using different technology, eg microarray and RNAseq, where one method does not assay all of the genes that another one does, but the networks are expected to be very similar; or when inferring networks describing distantly related species, in which case the networks are expected to be more different than similar. When orthology is not complete, we are interested in knowing if performance gains from fused regression are limited to those interactions which have fusion constraints. To test this, we used sets of 20 TF by 200 gene synthetic networks, with varying proportions of orthologous TFs and genes. We divided networks into those interactions with fusion constraints (interactions where there exist putative analogous interactions in the second network based off of the orthology mapping between TF, gene pairs), which we call the constrained subnetwork, and interactions without fusion constraints, which we refer to as the non-constrained subnetwork. We varied the weight on the fusion penalty, lamS, and evaluated performance by computing AUPR on the constrained subnetwork, the non-constrained subnetwork, and the whole network (Figure 1C). Since the conserved subgraphs were similar to each other (more like Figure 2A than 2B), we expected performance to improve as the fusion penalty weight increased. We observed this, particularly for the constrained subnetwork. As $\lambda_S$ increased, interactions with fusion constraints were encouraged to be more similar; growth in performance slowed as the differences in interaction weights approached zero, and the small amount of added noise to the expression data and slight differences between the conserved networks limited the recovery from reaching completeness. Interestingly, performance gains were seen even in the portion of the network that was unconstrained by fusion. By constraining part of an undetermined system, we obtained gains in even the unconstrained part. 


\subsection{Adaptive fusion successfully identifies and unfuses 'neofunctionalized' genes}
We recognize that orthology prediction is not a perfect proxy for functional conservation \cite{gabaldon_functional_2013, studer_how_2009, nehrt_testing_2011}. We implemented an adaptive fusion algorithm that attempts to optimize a nonconvex saturating penalty function on differences between fused interactions (Figure 3). Pairs of interactions which are very dissimilar even after fusion, which sit in the flat portion of this penalty function, are effectively ``unfused,'' and no further penalty is incurred as differences in interaction weights grow. Because our network inference problem is underdetermined, meaning that multiple networks would fit our data equally well, the ``unfusing'' or relaxation of the fusion penalty on constraints is convincing evidence for the rejection of a network which uses orthology to predict similarity in interaction weights. ''Unfusing'' suggests neofunctionalization of one or more of the genes involved in this pair of interactions.

We performed a simulation to assess the ability of our adaptive fusion algorithm to learn which parts of two input networks are conserved when orthologs are not functionally analogous  (Figure 4). We generated synthetic fused networks and introduced error in the fusion constraints by adding false positives and negatives to the orthology information given to the solver. Because we knew which entries in the orthology mapping were ``incorrect'' (not reflected in the generation of the networks), we could correctly label fusion constraints that involved one or more ``incorrect'' mappings. We verified that adaptive-fusion unfused mostly ``incorrectly fused'' interactions, while leaving truly analogous interactions fused (Figure 4a. Note that while pairs of interactions between true orthologs were sampled randomly so that the difference in interactions tended to be small, and pairs of interactions between incorrect orthologs were sampled randomly so that the difference in interactions tended to be large, there was an element of randomness in the sampling. This resulted in a small fraction of interactions between incorrect othologs being similar, and similarly, a small fraction of interactions between correct orthologs being different. Consequently, some interactions between incorrect orthologs remained fused and some interactions between correct orthologs were unfused. 

We compared the recovery of interaction weights which were accurately fused, and recovery of interaction weights which were inaccurately fused due to incorrect orthology information (Figure 4b). Because fused L2 heavily penalizes large differences between weights which are predicted to be similar, it is able to retrieve a more accurate network for those interactions with true fusion constraints than by learning networks separately. However, the gains accomplished by sharing information through fused regression do not extend to those interactions lacking true fusion constraints, and the error remains similar to learning networks separately. Because the penalty function used in adaptive fusion resembles that of fused L2 where differences in interactions are small (Figure 3), adaptive fusion's performance on accurately fused interactions is similar to that of fused L2. Because interactions which have been unfused remain underdetermined, we are not much closer to learning their values than if we learned networks separately. However, when using adaptive fusion, we are able to identify which interactions should not be similar, and therefore, which orthology mappings are not predictive of functional similarity. 


\subsection{Cross-species network inference using bacterial data}
We used gene-expression data from \textit{\textit{Bacillus subtilis}} and \textit{\textit{B. anthracis}} in order to assess performance gains of fused regression on real data. Our B subtilis data set consists of 360 time-series and steady-state observations of 4891 genes during development. Our \textit{\textit{B. anthracis}} dataset consists of 72 time-series and steady-state observations of 5536 genes comprising data from developmental and iron-starvation conditions. There were 247 known Transcription factors (TFs) in the \textit{\textit{B. subtilis}} dataset, and 248 TFs in the \textit{B. anthracis} dataset. 

We obtained 1870 one-to-one orthologs from Inparanoid \cite{ostlund_inparanoid_2010}, 95 of which are transcription factors, which produced 177,650 fusion-constraints between gene interactions within the two species. This number represents only $14.7\%$ of the regulatory interaction matrix in \textit{B. subtilis} and $12.9\%$ in \textit{B. anthracis}. The use of such dissimilar species is a test of whether fusion can improve network-inference even when the overlap in interactions is very small. 

In order to evaluate network inference performance, and for use as priors, we used a gold standard of 2896 known \textit{B. subtilis} interactions with corresponding activation and repression sign. Of these 2896 priors, 968 had corresponding interactions in \textit{B. anthracis}. Based on our simulation results, we can expect the greatest gains in network-inference performance from fusion when the species of interest has a small number of available conditions, but data is abundant in a related species. However, in order to evaluate performance objectively a gold-standard of known interactions is necessary. As a result, we can only evaluate network recovery for \textit{B. subtilis}, and \textit{B. subtilis} also has the majority of our conditions. In order to simulate the data-poor regime, we subsampled our \textit{B. subtilis} data. Specifically, we divided our \textit{B. subtilis} data into $k$ folds, and then for each fold fit a network to the \textit{B. subtilis} data from that fold alone fused to the entire 72 \textit{B. anthracis} conditions. We can then compute performance metrics (ie AUPR) for each fold, and use their variability across folds to test for significance of any improvements relating to the use of fusion constraints. 

When we applied fused L2 to our subsampled \textit{B. subtilis} and \textit{B. anthracis} datasets using optimized parameters, we did not see a significant improvement over solving the networks separately. Inspection of precision recall curves showed that there is increased precision at low values of recall. Essentially, precision increases for the high confidence part of the network but not for the low confidence part of the network. As a result, the improvements in performance may be more useful than would be suggested by AUPR alone. Interactions suggested by genome wide analysis are useful for target prediction, and the ranking of interactions produced by a network inference algorithms is a useful guide to what order these experiments should be carried out in. The high confidence part of the network represents interactions that are likely candidates for experimental validation, so improvement in recovery of these interactions is particularly useful in guiding research. 

\subsection{Within-species fusion using similarity of promoter region}
Information about the similarity of TF-gene interactions can also come from knowledge about the promoter region; this may be a better predictor of target similarity than orthology. In bacteria, genes within the same operon are under the control of the same promoter \cite{lawrence_shared_2002}. We predicted, therefore, that genes within the same operon will be regulated similarly by the same transcription factors. We applied fusion regression by creating fusion constraints between a given transcription factor and genes within the same operon, and showed a boost in \textit{B. subtilis} network recovery using within-species fusion (Figure 6b). 

\subsection{Integrating datasets using fusion regression}
Although there are many large-scale collaborations which attempt to make protocols as uniform as possible for comparability between datasets generated by different labs \cite{paten_nih_2015,kundaje_integrative_2015}, there still exists technical and biologial variability between many experiments attempting to capture the same or similar experimental condition. With the advent of new technology, such as RNAseq and single-cell RNAseq, microarray is no longer the dominant assay for genome-wide expression, but it is important to be able to combine datasets generated using different technologies. Currently, the most widely used approach to combining datasets for network inference is to learn networks from disparate datasets separately, then rank combine the networks as in Marbach et al \cite{marbach_revealing_2010}. We compared this approach to using fusion regression. We included, along with our \textit{B. subtilis} dataset, a previously published dataset containing 269 samples covering 104 conditions, obtained using a different tiling microarray (vs custom microarray) and different strain of \textit{B. subtilis} \cite{nicolas2012condition}. We compared performance when learning the networks separately, rank combining, and learning the networks simultaneously using fusion regression, and showed improvement on network inference using our fused L2 approach (Figure 6a). Importantly, our approach simultaneously learns multiple networks, rather than learning networks separately than combining into one. 

\subsection{Transcription factor activity estimation integrates into fusion regression approach}
We tested a combination of our fused regression approach with a method for estimating transcription factor activities (TFA). Rather than modeling gene expression using transcription factor mRNA abundance, we fit gene expression as a function of transcription factor activity, as shown in \textit{B. subtilis} by Arrieta-Ortiz et al \cite{arrieta-ortiz_experimentally_2015}. We estimated TFA based on known regulatory interactions using network component analysis \cite{liao2003network}. To test the integration of this approach with our fused regression, we asssesed the combination of \texti{B. subtilis} datasets, as in figure 6a, with the incorporation of TFA estimation. We randomly divided the prior known interactions in half, and used half to learn TFA. The rest we reserved as a gold standard for validation. As in previous studies, we observed a marked improvement in network inference when using transcription factor activity, which captures activation of transcription factor through mechanisms such as dimerization and interaction with required factors, over transcription factor expression level alone \cite{fu_reconstructing_2011}. We also obtained AUPR improvement when using fused regression on TFA, and showed that our gains from sharing information across datasets using fused regression were preserved and even enhanced by using TFA. 

\section{Discussion}
Gene expression data, such as microarray or RNA seq, provide information about the relationship between genes by allowing an experimenter to measure correlations in expression value over time or across conditions. Many sources of information - such as the knowledge that two genes are related through orthology or belong to the same operon - provide information about the relationships between these gene-gene relationships, without necessarily providing information about the gene-gene relationships themselves. For example, the meta information that two genes belong to the same operon suggests that they are likely to have a similar set of regulators \cite{lawrence_shared_2002}, but does little to inform the identity of those regulators. Meta-information about the structure of gene regulatory networks - specifically which pairs of interactions are \texti{a priori} likely to be similar to one another, can provide a powerful set of constraints to improve network inference performance. We present a general framework for gene regulatory network inference that incorporates this meta-information - termed fusion constraints - and apply the technique to the problem of simultaneous inference of regulatory networks in multiple species (\textit{B. subtilis} and \textit{B. anthracis}). We develop two algorithms for solving fused network inference problems, each of which has as its core the solving of a least-squares optimization problem with novel regularization constraints.

 The first method, fused L2, penalizes the squared difference of the regulatory weights of fused interactions. These constraints improve the performance of the underdetermined network inference problem, by allowing information to be shared across sources. We apply this algorithm to the problem of network inference in two distantly related biological organisms -- \textit{B. subtilis} and \textit{B. anthracis} -- and show that network recovery is improved through the introduction of fusion constraints between pairs of orthologous genes. Existing methods for cross-species network inference operate on the conserved subset of orthologous genes \cite{dillman_comparative_2015}. This may be appropriate with very closely related species, but could not be applied in this domain, where a large fraction (X\% and Y\%) of each species genomes do not have orthologs. Our method, in contrast, can obtain improvements in network inference performance even when the conserved subset of genes is small. We further demonstrate the viability of fused L2 as a method for combining data from multiple experimental platforms, where fusion is between each identical regulator-gene pair. Because the algorithm we developed can accomodate constraints between arbitrary pairs of regulatory interactions, any biological prior representing information about expected regulatory similarity can be represented, even if the prior provides no information about the magnitude or direction of regulation. We demonstrate this flexibility through the novel incorporation of operon structure into the gene-regulatory network inference problem. In this application, fusion reflects the assumption that genes in the same operons have similar regulators \cite{lawrence_shared_2002}. The ability to incorporate multiple data sets describing related processes, as well as multiple data types, in a principled manner, helps us take advantage of the breadth of experimentation in biology to better learn the structure of gene regulation. We illustrate this by combining two different \textit{B. subtilis} datasets and show that fused L2 is an improvement over current approaches to combining data \cite{marbach_revealing_2010} because of our ability to exploit the statistical power that our expanded datasets afford us. This approach is particularly interesting in light of the diversity of model organisms used in modern biology. Different model systems provide different advantages and disadvantages for experimental design \cite{stolfi_genetic_2012}, but without a principled mechanism for combining data from multiple sources, it is difficult to fully leverage data obtained from even a slightly different model system. 

Although it is important to take advantage of the similarities of related organisms for generating improved models of gene regulation, it is also critically important to understand how systems differ from one another. Our cross-species network inference method is premised on the assumption that orthologous genes have similar regulators. Existing approaches to the genome-wide testing of this assumption learn regulatory networks separately, then compare to identify conservation \cite{aytes_cross-species_2014, Wang2014a}. But because network inference is typically underconstrained, fitting a network that describes a particular set of experimental observations involves sampling a single network from a large set of networks that fit the data equally (or almost equally) as well. As a result, the existence of a difference between corresponding regulatory interactions in a pair of experimentally derived networks is weak evidence that a difference truly does exist. It may be that some other pair of networks exist that fit the data nearly as well, but do not exhibit this difference. As a result, global network inference algorithms are a very weak tool for uncovering evolutionary divergence. Our method, on the other hand, explicitly favors recovering networks for which evolutionarily corresponding interactions are similar. As a result, the failure to obtain networks that confirm evolutionary conservation is strong evidence that conservation does not exist; the next best network that does exhibit conservation must fit the data much worse to have overcome the bias built into the fusion constraints. 

Because our approach allows us to directly test -- and reject -- the hypothesis of conserved function, and because the enforcement of fusion constraints between non-conserved interactions may degrade network inference performance, we introduce an adaptive fusion method that decouples pairs of interactions for which expression data suggests a lack of conservation. Like the fused L2 approach, this method attempts to solve for networks which minimize a function that minimizes error in fitting the expression data plus error associated with the fusion penalty. In the case of cross-species network inference, orthology may provide a useful set of constraints on network structure. However, orthology does not always accurately predict functional similarity \cite{gabaldon_functional_2013}.When a fusion constraint encourages orthologous gene, TF pairs to share similar interactions across species, but the expression data suggests that these interaction weights should not be similar, the algorithm will arrive at some compromise between these two forces. If the disagreement arose because the genes involved have taken on new function through evolutionary divergence \cite{kellis_proof_2004}, network recovery would be improved had the fusion constraint not been enforced. We introduce a method -- adaptive fusion -- that attempts to learn which fusion constraints should be relaxed while the network is being learned. This method is based on minimizing a saturating penalty function on fusion constraints, similar to a class of penalties that have been developed to minimise bias in regularized regression \cite{fan2001variable,zhang2010nearly}. The result of adaptive fusion is both a network and a new set of fusion constraints, describing the learned conservation weights (including which fusion constraints have been relaxed). For the multiple species case, relaxation of fusion constraints represents orthologs which do not share similar interactions. When jointly learning networks describing processes in different cell lines, this may identify interesting context-specific behavior. Genes may be fused together on the basis of similar binding sites or chromatin features, and the relaxing of the fusion penalty indicates divergence of gene function. Adaptive fusion, therefore, is a tool for network inference as well as a method for testing network conservation. 

Because our model shares its basic assumptions about the role of transcription factors in gene expression dynamics with models developed for single-species network inference, we are able to leverage techniques developed for the single-species estimation of transctiption factor activity \cite{fu_reconstructing_2011}. The performance gains of this additional step in the cross-species case are significant.

Our approaches -- fused L2 and adaptive fusion -- represent a very general framework for simultaneous network inference and the incorporation of structured biological priors. These priors -- incorporated into our method as fusion constraints -- allow the use of rich sources of biological knowledge, such as orthology and operon structure, which have informed experimental design, but are typically not incorporated into genome wide network inference algorithms. By accomodating the simultaneous inference of multiple related networks, we can improve network inference performance by allowing the efficient reuse of data from similar, but not necessarily identical, sources. A method for pooling data from multiple sources holds the promise of vastly expanding the quantity of data available for analysis, particularly in less commonly used model systems. At the same time these methods allow us to test our assumptions on how similar biological systems relate to one another, by allowing us to rule out conservation in a principled way, and at a genome-wide scale. 


%One future aim is the ability to pick the $a$ parameter controlling the saturation point of the adaptive fusion penalty automatically from the expression data; this parameter is biologically interesting and indicates the difference in interaction weights which is great enough that the fusion constraints should be relaxed. An exhaustive search through different combinations of putative fusion constraints is prohibitive, but perhaps there is another way which avoids this. 


%\nocite{*}
\bibliographystyle{plain}
\bibliography{paper1.bib}


\end{document}


